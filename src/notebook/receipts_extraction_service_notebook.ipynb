{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4003903f",
   "metadata": {},
   "source": [
    "# Problem context\n",
    "\n",
    "## ETL Pipeline for Unstructured PDF Data Extraction\n",
    "\n",
    "### Overview\n",
    "This notebook implements an end-to-end ETL pipeline that extracts structured information from unstructured PDF files (text-based, tabular, and scanned images), transforms and cleans the data, loads it into a structured format, performs analysis, and generates automated reports.\n",
    "\n",
    "### Dataset Sources\n",
    "The pipeline processes three types of documents:\n",
    "\n",
    "1. **Jordan Construction Specifications** (`jordan_book/`)\n",
    "   - Text-heavy contract specification document\n",
    "   - Source: [Jordan 2019 Standard Specifications for Construction](https://clients.bolton-menk.com/jordanengineering/wp-content/uploads/sites/44/2019/12/Jordan-2019-Standard-Specifications-for-Construction.pdf)\n",
    "\n",
    "   ![image.png](contract.png)\n",
    "\n",
    "2. **Invoice Dataset** (`invoice_dataset/`)\n",
    "   - Invoices Images\n",
    "   -  Source: [Invoices Dataset from kaggle](https://www.kaggle.com/datasets/osamahosamabdellatif/high-quality-invoice-images-for-ocr)\n",
    "\n",
    "   ![image-2.png](invoice.png)\n",
    "\n",
    "   - Optmiziation Reference:\n",
    "      - https://www.kaggle.com/code/vermaavi/invoice-data-extraction-using-smolvlm\n",
    "\n",
    "\n",
    "3. **Receipts Dataset** (`receipts_dataset/`)\n",
    "   - Scanned receipts requiring OCR processing\n",
    "   - Receipts Images\n",
    "   - Source: [Receipts Dataset from Kaggle](https://www.kaggle.com/datasets/trainingdatapro/ocr-receipts-text-detection)\n",
    "\n",
    "   ![image-3.png](receipt.png)\n",
    "\n",
    "   - Optimization Reference:\n",
    "      - https://www.kaggle.com/code/gabrielvinicius/vision-models-llama-and-florence-2\n",
    "\n",
    "### Pipeline Components\n",
    "- **Extract**: Parse PDFs and extract key fields (IDs, names, descriptions, line items)\n",
    "- **Transform**: Normalize and clean data with consistent schema\n",
    "- **Load**: Store structured data for analysis\n",
    "- **Analyze**: Generate insights and statistics\n",
    "- **Report**: Automated report generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1637f9aa",
   "metadata": {},
   "source": [
    "# Proposed solution: AI Powered ETL Process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bedec39",
   "metadata": {},
   "source": [
    "## Libraries and Initial configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2009980e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI libraries\n",
    "from langgraph.graph import StateGraph, END, START\n",
    "from langchain_groq import ChatGroq  # Using Groq instead of OpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "# Data handling libraries\n",
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import TypedDict, Literal, Annotated\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "# Progress bar\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Logging and Tracing (Data Quality and Monitoring)\n",
    "import logging\n",
    "from langsmith import traceable\n",
    "\n",
    "# PDF processing libraries\n",
    "import pdfplumber  # text from PDFs\n",
    "import pytesseract  # OCR for scanned images\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "# Image encoding for Vision Models\n",
    "import base64\n",
    "\n",
    "# Visualization libraries\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b2a8b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(\"RECEIPTS-SERVICE__ai-powered-etl-process\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0bbf617",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-05 02:11:19,865 - root - INFO - Project Structure:\n",
      "2025-11-05 02:11:19,866 - root - INFO -   Base: /Users/viniciusgribas/Code/github/work/teste_alvorada_dev\n",
      "2025-11-05 02:11:19,867 - root - INFO -   Input: /Users/viniciusgribas/Code/github/work/teste_alvorada_dev/data/input\n",
      "2025-11-05 02:11:19,867 - root - INFO -   Output: /Users/viniciusgribas/Code/github/work/teste_alvorada_dev/data/output\n",
      "2025-11-05 02:11:19,867 - root - INFO -   Reports: /Users/viniciusgribas/Code/github/work/teste_alvorada_dev/reports\n",
      "2025-11-05 02:11:19,868 - root - INFO - \n",
      "Input Subdirectories:\n",
      "2025-11-05 02:11:19,868 - root - INFO -   Receipts: /Users/viniciusgribas/Code/github/work/teste_alvorada_dev/data/input/receipts_dataset\n",
      "2025-11-05 02:11:19,866 - root - INFO -   Base: /Users/viniciusgribas/Code/github/work/teste_alvorada_dev\n",
      "2025-11-05 02:11:19,867 - root - INFO -   Input: /Users/viniciusgribas/Code/github/work/teste_alvorada_dev/data/input\n",
      "2025-11-05 02:11:19,867 - root - INFO -   Output: /Users/viniciusgribas/Code/github/work/teste_alvorada_dev/data/output\n",
      "2025-11-05 02:11:19,867 - root - INFO -   Reports: /Users/viniciusgribas/Code/github/work/teste_alvorada_dev/reports\n",
      "2025-11-05 02:11:19,868 - root - INFO - \n",
      "Input Subdirectories:\n",
      "2025-11-05 02:11:19,868 - root - INFO -   Receipts: /Users/viniciusgribas/Code/github/work/teste_alvorada_dev/data/input/receipts_dataset\n"
     ]
    }
   ],
   "source": [
    "# DEFINITIONS\n",
    "\n",
    "# Define base paths\n",
    "BASE_DIR = Path.cwd().parent.parent  # Navigate up from notebook to project root\n",
    "DATA_INPUT = BASE_DIR / \"data\" / \"input\"\n",
    "DATA_OUTPUT = BASE_DIR / \"data\" / \"output\"\n",
    "REPORTS_DIR = BASE_DIR / \"reports\"\n",
    "\n",
    "# Define input subdirectories\n",
    "RECEIPTS_DIR = DATA_INPUT / \"receipts_dataset\"\n",
    "\n",
    "# Ensure output directories exist\n",
    "DATA_OUTPUT.mkdir(parents=True, exist_ok=True)\n",
    "REPORTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "logging.info(f\"Project Structure:\")\n",
    "logging.info(f\"  Base: {BASE_DIR}\")\n",
    "logging.info(f\"  Input: {DATA_INPUT}\")\n",
    "logging.info(f\"  Output: {DATA_OUTPUT}\")\n",
    "logging.info(f\"  Reports: {REPORTS_DIR}\")\n",
    "logging.info(f\"\\nInput Subdirectories:\")\n",
    "logging.info(f\"  Receipts: {RECEIPTS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4fa061",
   "metadata": {},
   "source": [
    "### Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "541cdbc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-05 02:11:19,879 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - ‚úÖ Vision Models Loaded:\n",
      "2025-11-05 02:11:19,879 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO -    Fast Vision: meta-llama/llama-4-scout-17b-16e-instruct\n",
      "2025-11-05 02:11:19,879 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO -    Reasoning Vision: meta-llama/llama-4-maverick-17b-128e-instruct\n",
      "2025-11-05 02:11:19,879 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO -    Fast Vision: meta-llama/llama-4-scout-17b-16e-instruct\n",
      "2025-11-05 02:11:19,879 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO -    Reasoning Vision: meta-llama/llama-4-maverick-17b-128e-instruct\n"
     ]
    }
   ],
   "source": [
    "# API Keys and environment variables configuration\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# ============================================================================\n",
    "# GROQ CONFIGURATION (FREE/CHEAP - NO MORE OPENAI!)\n",
    "# ============================================================================\n",
    "\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "if not GROQ_API_KEY:\n",
    "    raise ValueError(\n",
    "        \"‚ùå GROQ_API_KEY not found. \"\n",
    "    )\n",
    "\n",
    "# Model configurations from .env\n",
    "GROQ_FAST_MODEL= os.getenv(\"GROQ_FAST_MODEL\")\n",
    "GROQ_REASONING_MODEL = os.getenv(\"GROQ_REASONING_MODEL\")\n",
    "GROQ_VISION_MODEL = os.getenv(\"GROQ_FAST_VISION_TO_TEXT_MODEL\")  # Fixed: was GROQ_VISION_TO_TEXT_MODEL\n",
    "GROQ_VISION_REASONING_MODEL = os.getenv(\"GROQ_RESONING_VISION_TO_TEXT_MODEL\")  # Note: typo in .env (RESONING)\n",
    "GROQ_TEMPERATURE = float(os.getenv(\"GROQ_DEFAULT_TEMPERATURE\", \"0.1\"))\n",
    "\n",
    "logger.info(f\"‚úÖ Vision Models Loaded:\")\n",
    "logger.info(f\"   Fast Vision: {GROQ_VISION_MODEL}\")\n",
    "logger.info(f\"   Reasoning Vision: {GROQ_VISION_REASONING_MODEL}\")\n",
    "\n",
    "# Initialize Groq LLM for text/structured output (via LangChain)\n",
    "llm_fast = ChatGroq(\n",
    "    model=GROQ_FAST_MODEL,\n",
    "    temperature=GROQ_TEMPERATURE,\n",
    "    api_key=GROQ_API_KEY,\n",
    ")\n",
    "\n",
    "llm_reasoning = ChatGroq(\n",
    "    model=GROQ_REASONING_MODEL,\n",
    "    temperature=GROQ_TEMPERATURE,\n",
    "    api_key=GROQ_API_KEY,\n",
    ")\n",
    "\n",
    "llm_vision = ChatGroq(\n",
    "    model=GROQ_VISION_MODEL,\n",
    "    temperature=GROQ_TEMPERATURE,\n",
    "    api_key=GROQ_API_KEY,\n",
    ")\n",
    "\n",
    "llm_vision_reasoning = ChatGroq(\n",
    "    model=GROQ_VISION_REASONING_MODEL,\n",
    "    temperature=GROQ_TEMPERATURE,\n",
    "    api_key=GROQ_API_KEY,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "067fbed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-05 02:11:20,508 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-05 02:11:20,526 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - üß™ Test Response: Groq is working!\n",
      "2025-11-05 02:11:20,526 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - üß™ Test Response: Groq is working!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "response_test = llm_fast.invoke([HumanMessage(content=\"Say 'Groq is working!' in one sentence.\")])\n",
    "logger.info(f\"üß™ Test Response: {response_test.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e078237a",
   "metadata": {},
   "source": [
    "## States"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7420d1db",
   "metadata": {},
   "source": [
    "### Pydantic Schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dc2ace1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-05 02:11:20,541 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - ‚úÖ Receipt Schema defined for Vision Model extraction\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional, List\n",
    "\n",
    "\n",
    "# Line Item model (shared by all document types)\n",
    "class LineItem(BaseModel):\n",
    "    \"\"\"Represents a single line item in an invoice, receipt, or contract.\"\"\"\n",
    "    description: str = Field(..., description=\"Item/service/product description\")\n",
    "    quantity: float = Field(..., description=\"Quantity purchased or contracted\")\n",
    "    unit_price: float = Field(..., description=\"Price per unit\")\n",
    "    taxes: Optional[float] = Field(0.0, description=\"Applicable taxes on the line item\")\n",
    "    discount: Optional[float] = Field(0.0, description=\"Applicable discounts on the line item\")\n",
    "    total: float = Field(..., description=\"Total amount (quantity √ó unit_price)\")\n",
    "\n",
    "\n",
    "# Receipt Schema as Pydantic Model (PRIMARY FOCUS - Vision Model)\n",
    "class ReceiptSchema(BaseModel):\n",
    "    \"\"\"Schema for receipt documents - extracted via Groq Vision Model.\"\"\"\n",
    "    document_id: str = Field(..., description=\"Receipt number or transaction ID\")\n",
    "    contractor_name: str = Field(..., description=\"Store/merchant name\")\n",
    "    client_name: Optional[str] = Field(None, description=\"Customer name (usually null for receipts)\")\n",
    "    date: str = Field(..., description=\"Purchase date in YYYY-MM-DD format\")\n",
    "    total_value: float = Field(..., description=\"Total amount paid\")\n",
    "    taxes: Optional[float] = Field(0.0, description=\"Applicable taxes on the receipt\")\n",
    "    discount: Optional[float] = Field(0.0, description=\"Applicable discounts on the receipt\")\n",
    "    currency: str = Field(default=\"USD\", description=\"Currency code\")\n",
    "    description: Optional[str] = Field(None, description=\"Store location or additional notes\")\n",
    "    line_items: List[LineItem] = Field(default_factory=list, description=\"List of purchased items\")\n",
    "    \n",
    "    def check_retry_placeholders(self) -> tuple[bool, List[str]]:\n",
    "        \"\"\"Check if extraction has <RETRY> placeholders and identify incomplete fields.\"\"\"\n",
    "        incomplete = []\n",
    "        data_str = str(self.model_dump())\n",
    "        \n",
    "        if '<RETRY>' not in data_str:\n",
    "            return False, []\n",
    "        \n",
    "        # Check each field for <RETRY> placeholder\n",
    "        for field_name, field_value in self.model_dump().items():\n",
    "            if '<RETRY>' in str(field_value):\n",
    "                incomplete.append(field_name)\n",
    "        \n",
    "        return True, incomplete\n",
    "\n",
    "\n",
    "logger.info(\"‚úÖ Receipt Schema defined for Vision Model extraction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a61328",
   "metadata": {},
   "source": [
    "###  MODELS AND DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "107d2c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kg/tvsv7wgn655fvxmmzsc_lds00000gn/T/ipykernel_69298/3768840889.py:9: MovedIn20Warning: The ``declarative_base()`` function is now available as sqlalchemy.orm.declarative_base(). (deprecated since: 2.0) (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)\n",
      "  Base = declarative_base()\n",
      "2025-11-05 02:11:20,655 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - ‚úÖ Receipt Database Schema defined (SQLAlchemy ORM)\n",
      "2025-11-05 02:11:20,655 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO -    Tables: contractors, receipts, line_items\n",
      "2025-11-05 02:11:20,655 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO -    NORMALIZED design: line_items -> receipts (FK)\n",
      "2025-11-05 02:11:20,655 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO -    Schema: line_items table has receipt_id foreign key\n",
      "2025-11-05 02:11:20,655 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO -    Tables: contractors, receipts, line_items\n",
      "2025-11-05 02:11:20,655 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO -    NORMALIZED design: line_items -> receipts (FK)\n",
      "2025-11-05 02:11:20,655 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO -    Schema: line_items table has receipt_id foreign key\n"
     ]
    }
   ],
   "source": [
    "# SQLAlchemy Schema for Receipts Only - NORMALIZED DESIGN\n",
    "# Receipts table is the FACT table, line_items reference receipts\n",
    "\n",
    "from sqlalchemy import create_engine, Column, Integer, String, Float, Date, Text, ForeignKey, Boolean\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker, relationship\n",
    "from datetime import datetime as dt\n",
    "\n",
    "Base = declarative_base()\n",
    "\n",
    "# ============================================================================\n",
    "# RECEIPTS DATABASE SCHEMA - NORMALIZED (Standard Design)\n",
    "# ============================================================================\n",
    "\n",
    "class Contractor(Base):\n",
    "    \"\"\"Stores/Merchants table - normalized to avoid duplication.\"\"\"\n",
    "    __tablename__ = 'contractors'\n",
    "    \n",
    "    id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    name = Column(String(255), unique=True, nullable=False, index=True)\n",
    "    total_receipts = Column(Integer, default=0)\n",
    "    total_spent = Column(Float, default=0.0)\n",
    "    created_at = Column(Date, default=dt.now().date)\n",
    "    \n",
    "    # Relationship\n",
    "    receipts = relationship(\"Receipt\", back_populates=\"contractor\")\n",
    "\n",
    "\n",
    "class Receipt(Base):\n",
    "    \"\"\"FACT table - main receipts table (maps to ReceiptSchema Pydantic model).\"\"\"\n",
    "    __tablename__ = 'receipts'\n",
    "    \n",
    "    id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    \n",
    "    # Receipt identification\n",
    "    document_id = Column(String(255), nullable=False, index=True)\n",
    "    filename = Column(String(255), nullable=False)\n",
    "    \n",
    "    # Foreign Key to Contractor\n",
    "    contractor_id = Column(Integer, ForeignKey('contractors.id'), nullable=False)\n",
    "    \n",
    "    # Receipt data (from ReceiptSchema)\n",
    "    date = Column(Date, nullable=False)\n",
    "    total_value = Column(Float, nullable=False)\n",
    "    taxes = Column(Float, default=0.0)\n",
    "    discount = Column(Float, default=0.0)\n",
    "    currency = Column(String(10), default='USD')\n",
    "    description = Column(Text, nullable=True)\n",
    "    \n",
    "    # Extraction metadata\n",
    "    extraction_method = Column(String(100), nullable=False)\n",
    "    file_size_kb = Column(Float, nullable=True)\n",
    "    needs_retry = Column(Boolean, default=False)\n",
    "    \n",
    "    created_at = Column(Date, default=dt.now().date)\n",
    "    \n",
    "    # Relationships\n",
    "    contractor = relationship(\"Contractor\", back_populates=\"receipts\")\n",
    "    line_items = relationship(\"LineItem\", back_populates=\"receipt\", cascade=\"all, delete-orphan\")\n",
    "\n",
    "\n",
    "class LineItem(Base):\n",
    "    \"\"\"Line items table - details for each receipt (maps to LineItem Pydantic model).\"\"\"\n",
    "    __tablename__ = 'line_items'\n",
    "    \n",
    "    id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    \n",
    "    # Foreign Key to Receipt\n",
    "    receipt_id = Column(Integer, ForeignKey('receipts.id'), nullable=False)\n",
    "    \n",
    "    # Line item data (from LineItem Pydantic model)\n",
    "    description = Column(Text, nullable=False)\n",
    "    quantity = Column(Float, nullable=False)\n",
    "    unit_price = Column(Float, nullable=False)\n",
    "    taxes = Column(Float, default=0.0)\n",
    "    discount = Column(Float, default=0.0)\n",
    "    total = Column(Float, nullable=False)\n",
    "    \n",
    "    created_at = Column(Date, default=dt.now().date)\n",
    "    \n",
    "    # Relationship\n",
    "    receipt = relationship(\"Receipt\", back_populates=\"line_items\")\n",
    "\n",
    "\n",
    "logger.info(\"‚úÖ Receipt Database Schema defined (SQLAlchemy ORM)\")\n",
    "logger.info(\"   Tables: contractors, receipts, line_items\")\n",
    "logger.info(\"   NORMALIZED design: line_items -> receipts (FK)\")\n",
    "logger.info(\"   Schema: line_items table has receipt_id foreign key\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90e76e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-05 02:11:20,666 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - ‚úÖ Receipt database load function defined (denormalized schema)\n"
     ]
    }
   ],
   "source": [
    "def load_receipts_to_database(df: pd.DataFrame) -> dict:\n",
    "    \"\"\"\n",
    "    üóÑÔ∏è Load validated receipt data to Supabase PostgreSQL (DENORMALIZED SCHEMA).\n",
    "    \n",
    "    Takes validated_df with extracted receipt data and stores in denormalized database:\n",
    "    - contractors: Unique stores/merchants\n",
    "    - line_items: Individual items (dimension table)\n",
    "    - receipts: Receipt transactions (FACT table with FK to contractors AND line_items)\n",
    "    \n",
    "    Each receipt row will have a line_item_id, creating multiple receipt rows per original receipt.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with 'success'=True and 'extracted_data' (ReceiptSchema)\n",
    "    \n",
    "    Returns:\n",
    "        dict with load statistics and connection info\n",
    "    \"\"\"\n",
    "    if df is None or len(df) == 0:\n",
    "        logger.warning(\"‚ùå No data to load\")\n",
    "        return {\"error\": \"No data provided\"}\n",
    "    \n",
    "    # Get Supabase connection from .env\n",
    "    db_url = os.getenv(\"DATABASE_URL\")\n",
    "    if not db_url:\n",
    "        logger.error(\"‚ùå DATABASE_URL not found in .env file\")\n",
    "        return {\"error\": \"DATABASE_URL not configured\"}\n",
    "    \n",
    "    logger.info(\"=\"*80)\n",
    "    logger.info(\"üóÑÔ∏è  LOADING RECEIPTS TO SUPABASE (DENORMALIZED)\")\n",
    "    logger.info(\"=\"*80)\n",
    "    logger.info(f\"Database: {db_url.split('@')[-1]}\")\n",
    "    \n",
    "    try:\n",
    "        # Create engine and tables\n",
    "        engine = create_engine(db_url, echo=False)\n",
    "        Base.metadata.create_all(engine)\n",
    "        logger.info(\"‚úÖ Database tables created/verified (denormalized schema)\")\n",
    "        \n",
    "        # Create session\n",
    "        Session = sessionmaker(bind=engine)\n",
    "        session = Session()\n",
    "        \n",
    "        # Filter only successful extractions\n",
    "        successful_df = df[df['success'] == True].copy()\n",
    "        \n",
    "        if len(successful_df) == 0:\n",
    "            logger.warning(\"‚ö†Ô∏è  No successful extractions to load\")\n",
    "            session.close()\n",
    "            return {\"warning\": \"No successful extractions\"}\n",
    "        \n",
    "        logger.info(f\"üìä Loading {len(successful_df)} receipts (denormalized)...\")\n",
    "        \n",
    "        # Statistics\n",
    "        contractors_added = 0\n",
    "        receipts_added = 0\n",
    "        line_items_added = 0\n",
    "        contractor_cache = {}\n",
    "        \n",
    "        # Process each receipt\n",
    "        for idx, row in successful_df.iterrows():\n",
    "            try:\n",
    "                extracted = row['extracted_data']\n",
    "                if not extracted:\n",
    "                    continue\n",
    "                \n",
    "                contractor_name = extracted.get('contractor_name', 'Unknown')\n",
    "                \n",
    "                # Get or create contractor\n",
    "                if contractor_name not in contractor_cache:\n",
    "                    contractor = session.query(Contractor).filter_by(name=contractor_name).first()\n",
    "                    if not contractor:\n",
    "                        contractor = Contractor(name=contractor_name)\n",
    "                        session.add(contractor)\n",
    "                        session.flush()\n",
    "                        contractors_added += 1\n",
    "                        logger.info(f\"   ‚ûï New contractor: {contractor_name}\")\n",
    "                    contractor_cache[contractor_name] = contractor\n",
    "                else:\n",
    "                    contractor = contractor_cache[contractor_name]\n",
    "                \n",
    "                # Parse date\n",
    "                date_str = extracted.get('date', '')\n",
    "                try:\n",
    "                    receipt_date = dt.strptime(date_str, '%Y-%m-%d').date()\n",
    "                except:\n",
    "                    receipt_date = dt.now().date()\n",
    "                \n",
    "                # Get line items\n",
    "                line_items_data = extracted.get('line_items', [])\n",
    "                \n",
    "                # If no line items, create a dummy one to avoid empty receipts\n",
    "                if not line_items_data:\n",
    "                    line_items_data = [{\n",
    "                        'description': 'No line items extracted',\n",
    "                        'quantity': 1.0,\n",
    "                        'unit_price': extracted.get('total_value', 0.0),\n",
    "                        'taxes': extracted.get('taxes', 0.0),\n",
    "                        'discount': extracted.get('discount', 0.0),\n",
    "                        'total': extracted.get('total_value', 0.0)\n",
    "                    }]\n",
    "                \n",
    "                # Create one receipt row per line item (DENORMALIZED)\n",
    "                for item_data in line_items_data:\n",
    "                    # Create line item first\n",
    "                    line_item = LineItem(\n",
    "                        description=item_data.get('description', ''),\n",
    "                        quantity=float(item_data.get('quantity', 1.0)),\n",
    "                        unit_price=float(item_data.get('unit_price', 0.0)),\n",
    "                        taxes=float(item_data.get('taxes', 0.0)),\n",
    "                        discount=float(item_data.get('discount', 0.0)),\n",
    "                        total=float(item_data.get('total', 0.0))\n",
    "                    )\n",
    "                    session.add(line_item)\n",
    "                    session.flush()  # Get line_item.id\n",
    "                    line_items_added += 1\n",
    "                    \n",
    "                    # Create receipt with FK to line_item\n",
    "                    receipt = Receipt(\n",
    "                        document_id=extracted.get('document_id', row['filename']),\n",
    "                        filename=row['filename'],\n",
    "                        contractor_id=contractor.id,\n",
    "                        line_item_id=line_item.id,  # FK to line_items\n",
    "                        date=receipt_date,\n",
    "                        total_value=float(extracted.get('total_value', 0.0)),\n",
    "                        taxes=float(extracted.get('taxes', 0.0)),\n",
    "                        discount=float(extracted.get('discount', 0.0)),\n",
    "                        currency=extracted.get('currency', 'USD'),\n",
    "                        description=extracted.get('description'),\n",
    "                        extraction_method=row['extraction_method'],\n",
    "                        file_size_kb=row.get('file_size_kb'),\n",
    "                        needs_retry=row.get('needs_retry', False)\n",
    "                    )\n",
    "                    session.add(receipt)\n",
    "                    receipts_added += 1\n",
    "                    \n",
    "                    # Update contractor totals (only once per original receipt, not per line)\n",
    "                    if item_data == line_items_data[0]:  # First line item only\n",
    "                        contractor.total_receipts += 1\n",
    "                        contractor.total_spent += receipt.total_value\n",
    "                \n",
    "                # Commit every 10 original receipts\n",
    "                if (idx + 1) % 10 == 0:\n",
    "                    session.commit()\n",
    "                    logger.info(f\"   üíæ Committed {idx + 1} original receipts ({receipts_added} rows)...\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                logger.error(f\"   ‚ùå Error loading {row['filename']}: {e}\")\n",
    "                session.rollback()\n",
    "                continue\n",
    "        \n",
    "        # Final commit\n",
    "        session.commit()\n",
    "        session.close()\n",
    "        \n",
    "        logger.info(\"=\"*80)\n",
    "        logger.info(\"‚úÖ DATABASE LOAD COMPLETE (DENORMALIZED)\")\n",
    "        logger.info(\"=\"*80)\n",
    "        logger.info(f\"   Contractors: {contractors_added} new, {len(contractor_cache)} total\")\n",
    "        logger.info(f\"   Line Items: {line_items_added} (dimension table)\")\n",
    "        logger.info(f\"   Receipts: {receipts_added} rows (FACT table)\")\n",
    "        logger.info(f\"   Note: Multiple receipt rows per original document\")\n",
    "        logger.info(\"=\"*80)\n",
    "        \n",
    "        return {\n",
    "            \"success\": True,\n",
    "            \"contractors_added\": contractors_added,\n",
    "            \"contractors_total\": len(contractor_cache),\n",
    "            \"receipts_added\": receipts_added,\n",
    "            \"line_items_added\": line_items_added,\n",
    "            \"database\": db_url.split('@')[-1]\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Database error: {e}\")\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "\n",
    "logger.info(\"‚úÖ Receipt database load function defined (denormalized schema)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11460e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to list image and PDF files in a directory\n",
    "def list_input_files(directory: Path, max_files: int = None) -> list[Path]:\n",
    "    \"\"\"\n",
    "    List PDF and image files (jpg, jpeg, png) in a directory.\n",
    "    \n",
    "    Args:\n",
    "        directory: Path to directory\n",
    "        max_files: Maximum number of files to return (None = all)\n",
    "    \n",
    "    Returns:\n",
    "        List of file paths\n",
    "    \"\"\"\n",
    "    if not directory.exists():\n",
    "        logger.warning(f\"‚ö†Ô∏è  Directory not found: {directory}\")\n",
    "        return []\n",
    "    \n",
    "    # Support both PDFs and images\n",
    "    files = []\n",
    "    for extension in [\"*.pdf\", \"*.jpg\", \"*.jpeg\", \"*.png\", \"*.JPG\", \"*.JPEG\", \"*.PNG\"]:\n",
    "        files.extend(directory.glob(extension))\n",
    "    \n",
    "    files = sorted(files)\n",
    "    \n",
    "    if max_files:\n",
    "        files = files[:max_files]\n",
    "    \n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c6e867d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for text cleaning\n",
    "def clean_raw_text(raw_text: str) -> str:\n",
    "    \"\"\"Clean up OCR artifacts and formatting issues.\"\"\"\n",
    "    text = re.sub(r\"[_]{2,}\", \" \", raw_text)\n",
    "    text = re.sub(r\"([A-Za-z])[_]+([A-Za-z])\", r\"\\1\\2\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    return text.strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707f2e95",
   "metadata": {},
   "source": [
    "## Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4817dc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Receipt Extraction Prompt for Vision Model\n",
    "RECEIPT_EXTRACTION_PROMPT = \"\"\"Extract ALL information from this receipt image into JSON format.\n",
    "\n",
    "You MUST return a valid JSON object with this structure:\n",
    "{\n",
    "  \"document_id\": \"receipt/transaction number (if visible, otherwise generate from store+date)\",\n",
    "  \"contractor_name\": \"store/merchant name\",\n",
    "  \"client_name\": null,\n",
    "  \"date\": \"YYYY-MM-DD format\",\n",
    "  \"total_value\": numeric_total_as_float,\n",
    "  \"currency\": \"USD\",\n",
    "  \"description\": \"store location or address\",\n",
    "  \"line_items\": [\n",
    "    {\n",
    "      \"description\": \"exact item name from receipt\",\n",
    "      \"quantity\": 1.0,\n",
    "      \"unit_price\": price_per_item,\n",
    "      \"taxes\": 0.0,\n",
    "      \"discount\": 0.0,\n",
    "      \"total\": total_price_for_line\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "CRITICAL RULES:\n",
    "1. Extract ALL visible line items from the receipt\n",
    "2. Use exact product names, not generic descriptions\n",
    "3. Ensure total_value matches the receipt total\n",
    "4. Return ONLY the JSON object, no markdown formatting\n",
    "5. All numeric values must be floats (no strings)\n",
    "6. If date format is unclear, use YYYY-MM-DD format\n",
    "7. If some field is not visible, put the placeholder <RETRY>, so other agent can try again.\n",
    "\n",
    "Extract the data now:\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "307e39fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Receipt VALIDATION Prompt for Vision Reasoning Model\n",
    "RECEIPT_VALIDATION_PROMPT = \"\"\"You are a SPECIALIST in analyzing receipts with EXTREME ATTENTION TO DETAIL.\n",
    "\n",
    "A previous extraction attempt either FAILED or returned incomplete data with <RETRY> placeholders.\n",
    "\n",
    "Your task: Carefully examine this receipt image and extract ALL information with MAXIMUM PRECISION.\n",
    "\n",
    "Return a valid JSON object with this EXACT structure:\n",
    "{\n",
    "  \"document_id\": \"receipt/transaction number (extract from image, or generate unique ID from store+date+time)\",\n",
    "  \"contractor_name\": \"EXACT store/merchant name as shown\",\n",
    "  \"client_name\": null,\n",
    "  \"date\": \"YYYY-MM-DD (parse any date format carefully)\",\n",
    "  \"total_value\": numeric_total_as_float,\n",
    "  \"taxes\": total_taxes_as_float_or_0.0,\n",
    "  \"discount\": total_discount_as_float_or_0.0,\n",
    "  \"currency\": \"USD (or detected currency)\",\n",
    "  \"description\": \"store location/address/additional context\",\n",
    "  \"line_items\": [\n",
    "    {\n",
    "      \"description\": \"EXACT product name (not generic, be specific)\",\n",
    "      \"quantity\": float_quantity,\n",
    "      \"unit_price\": float_price,\n",
    "      \"taxes\": float_line_taxes_or_0.0,\n",
    "      \"discount\": float_line_discount_or_0.0,\n",
    "      \"total\": float_total_for_line\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "CRITICAL INSTRUCTIONS FOR DEEP ANALYSIS:\n",
    "1. **READ CAREFULLY**: Analyze every pixel, every number, every character\n",
    "2. **LINE ITEMS**: Extract EVERY SINGLE item - do not skip or generalize\n",
    "3. **PRODUCT NAMES**: Use EXACT names from receipt (not \"Item\", \"Product\", etc.)\n",
    "4. **NUMBERS**: Verify all calculations match (line totals, subtotals, taxes, final total)\n",
    "5. **DATES**: Parse any date format (MM/DD/YY, DD-MM-YYYY, etc.) ‚Üí convert to YYYY-MM-DD\n",
    "6. **AMBIGUOUS TEXT**: If text is unclear, make best educated guess based on context\n",
    "7. **MISSING DATA**: Only use null/0.0 if truly not visible (do NOT use <RETRY>)\n",
    "8. **JSON ONLY**: Return ONLY the JSON object with no markdown, no explanation\n",
    "\n",
    "REASON STEP-BY-STEP:\n",
    "- First, identify store name and date\n",
    "- Then, locate total amount\n",
    "- Next, extract ALL line items systematically\n",
    "- Finally, verify totals match\n",
    "\n",
    "Extract the data now with EXTREME PRECISION:\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bfecff",
   "metadata": {},
   "source": [
    "## Nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dec5ad9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_receipts_vision_node(state: dict) -> dict:\n",
    "    \"\"\"\n",
    "    üî• SIMPLIFIED NODE: Extract receipts using Groq Vision Model (Scout) via LangChain.\n",
    "    \n",
    "    NO OCR! Direct image ‚Üí Vision LLM ‚Üí Structured JSON ‚Üí Pydantic validation.\n",
    "    Uses LangChain's llm_vision with proper message formatting.\n",
    "    Uses list-of-dicts processing to avoid DataFrame mutation issues.\n",
    "    \n",
    "    Args:\n",
    "        state: Must contain \"receipt_input_path\" (str)\n",
    "    \n",
    "    Returns:\n",
    "        dict with:\n",
    "            - receipts_df: DataFrame with extracted data\n",
    "            - errors: List of error messages\n",
    "    \"\"\"\n",
    "    receipts_dir = Path(state.get(\"receipt_input_path\"))\n",
    "    \n",
    "    # Get all receipt files\n",
    "    receipt_files = list_input_files(receipts_dir)\n",
    "    \n",
    "    if not receipt_files:\n",
    "        logger.warning(f\"No receipt files found in {receipts_dir}\")\n",
    "        return {\"receipts_df\": pd.DataFrame(), \"errors\": [\"No receipt files found\"]}\n",
    "    \n",
    "    logger.info(f\"üì∏ Processing {len(receipt_files)} receipts with Vision Model (LangChain)...\")\n",
    "    \n",
    "    receipts_data = []\n",
    "    \n",
    "    for idx, file_path in enumerate(receipt_files, start=1):\n",
    "        logger.info(f\"[{idx}/{len(receipt_files)}] Processing: {file_path.name}\")\n",
    "        \n",
    "        try:\n",
    "            file_ext = file_path.suffix.lower()\n",
    "            \n",
    "            # Only process images (PDF support can be added later)\n",
    "            if file_ext not in [\".jpg\", \".jpeg\", \".png\"]:\n",
    "                logger.warning(f\"Skipping unsupported file type: {file_ext}\")\n",
    "                receipts_data.append({\n",
    "                    \"filename\": file_path.name,\n",
    "                    \"file_path\": str(file_path),\n",
    "                    \"extraction_method\": \"SKIPPED\",\n",
    "                    \"success\": False,\n",
    "                    \"needs_retry\": False,\n",
    "                    \"incomplete_fields\": [],\n",
    "                    \"error\": f\"Unsupported file type: {file_ext}\",\n",
    "                    \"extracted_data\": None\n",
    "                })\n",
    "                continue\n",
    "            \n",
    "            # Read image and convert to base64\n",
    "            with open(file_path, 'rb') as img_file:\n",
    "                image_bytes = img_file.read()\n",
    "                image_base64 = base64.b64encode(image_bytes).decode('utf-8')\n",
    "            \n",
    "            # Determine MIME type\n",
    "            mime_types = {'.jpg': 'image/jpeg', '.jpeg': 'image/jpeg', '.png': 'image/png'}\n",
    "            mime_type = mime_types.get(file_ext, 'image/jpeg')\n",
    "            \n",
    "            # Build message with image using LangChain format\n",
    "            message = HumanMessage(\n",
    "                content=[\n",
    "                    {\"type\": \"text\", \"text\": RECEIPT_EXTRACTION_PROMPT},\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\"url\": f\"data:{mime_type};base64,{image_base64}\"}\n",
    "                    }\n",
    "                ]\n",
    "            )\n",
    "            \n",
    "            # Call Vision Model via LangChain\n",
    "            response = llm_vision.invoke([message])\n",
    "            raw_response = response.content\n",
    "            \n",
    "            # Clean markdown if present\n",
    "            clean_json = raw_response.strip()\n",
    "            if clean_json.startswith(\"```\"):\n",
    "                clean_json = clean_json.split(\"```\")[1]\n",
    "                if clean_json.startswith(\"json\"):\n",
    "                    clean_json = clean_json[4:]\n",
    "                clean_json = clean_json.strip()\n",
    "            \n",
    "            # Parse JSON and validate with Pydantic\n",
    "            try:\n",
    "                data = json.loads(clean_json)\n",
    "            except json.JSONDecodeError as json_err:\n",
    "                logger.error(f\"   ‚ùå JSON parsing failed for {file_path.name}: {json_err}\")\n",
    "                logger.error(f\"   Raw response preview: {raw_response[:200]}...\")\n",
    "                receipts_data.append({\n",
    "                    \"filename\": file_path.name,\n",
    "                    \"file_path\": str(file_path),\n",
    "                    \"extraction_method\": \"Vision (FAILED - Invalid JSON)\",\n",
    "                    \"success\": False,\n",
    "                    \"needs_retry\": False,\n",
    "                    \"incomplete_fields\": [],\n",
    "                    \"error\": f\"JSON decode error: {str(json_err)}\",\n",
    "                    \"extracted_data\": None\n",
    "                })\n",
    "                continue  # Skip to next file\n",
    "            \n",
    "            # Validate with Pydantic\n",
    "            validated = ReceiptSchema.model_validate(data)\n",
    "            \n",
    "            # Check for incomplete fields\n",
    "            needs_retry, incomplete_fields = validated.check_retry_placeholders()\n",
    "            \n",
    "            # Success!\n",
    "            receipts_data.append({\n",
    "                \"filename\": file_path.name,\n",
    "                \"file_path\": str(file_path),\n",
    "                \"file_size_kb\": file_path.stat().st_size / 1024,\n",
    "                \"extraction_method\": f\"Vision ({GROQ_VISION_MODEL})\",\n",
    "                \"success\": True,\n",
    "                \"needs_retry\": needs_retry,\n",
    "                \"incomplete_fields\": incomplete_fields if needs_retry else [],\n",
    "                \"error\": None,\n",
    "                \"extracted_data\": validated.model_dump()\n",
    "            })\n",
    "            \n",
    "            if needs_retry:\n",
    "                logger.info(f\"   ‚ö†Ô∏è  Extracted with <RETRY> fields: {validated.contractor_name} - {incomplete_fields}\")\n",
    "            else:\n",
    "                logger.info(f\"   ‚úÖ Extracted: {validated.contractor_name} - ${validated.total_value}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"   ‚ùå Error processing {file_path.name}: {e}\")\n",
    "            receipts_data.append({\n",
    "                \"filename\": file_path.name,\n",
    "                \"file_path\": str(file_path),\n",
    "                \"extraction_method\": \"Vision (FAILED)\",\n",
    "                \"success\": False,\n",
    "                \"needs_retry\": False,\n",
    "                \"incomplete_fields\": [],\n",
    "                \"error\": str(e),\n",
    "                \"extracted_data\": None\n",
    "            })\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(receipts_data)\n",
    "    successful = df['success'].sum()\n",
    "    \n",
    "    logger.info(\"=\"*80)\n",
    "    logger.info(f\"‚úÖ Vision Model Extraction Complete:\")\n",
    "    logger.info(f\"   Total: {len(df)} receipts\")\n",
    "    logger.info(f\"   Successful: {successful} ({successful/len(df)*100:.1f}%)\")\n",
    "    logger.info(f\"   Failed: {len(df) - successful}\")\n",
    "    logger.info(\"=\"*80)\n",
    "    \n",
    "    return {\n",
    "        **state,\n",
    "        \"receipts_df\": df,\n",
    "        \"errors\": state.get(\"errors\", [])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23720c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def receipt_validator_manager(state: dict) -> dict:\n",
    "    \"\"\"\n",
    "    üîç VALIDATION & RETRY NODE: Deep analysis for failed or incomplete extractions.\n",
    "    \n",
    "    Uses REASONING Vision Model (Maverick) for:\n",
    "    1. Failed extractions (success=False)\n",
    "    2. Successful extractions with <RETRY> placeholders (needs_retry=True)\n",
    "    \n",
    "    This node provides DEEP REASONING and CAREFUL ANALYSIS.\n",
    "    Uses list-of-dicts processing to avoid DataFrame mutation issues.\n",
    "    \n",
    "    Args:\n",
    "        state: Must contain \"receipts_df\" (DataFrame from extract_receipts_vision_node)\n",
    "    \n",
    "    Returns:\n",
    "        dict with:\n",
    "            - receipts_df: Updated DataFrame with reprocessed items\n",
    "            - validation_summary: Statistics about validation process\n",
    "    \"\"\"\n",
    "    df = state.get(\"receipts_df\")\n",
    "    \n",
    "    if df is None or len(df) == 0:\n",
    "        logger.warning(\"No receipts DataFrame found in state\")\n",
    "        return state\n",
    "    \n",
    "    # Convert DataFrame to list of dicts for processing\n",
    "    receipts_list = df.to_dict('records')\n",
    "    \n",
    "    # Identify items needing validation\n",
    "    items_to_validate = []\n",
    "    for idx, item in enumerate(receipts_list):\n",
    "        if not item['success'] or item.get('needs_retry', False):\n",
    "            items_to_validate.append((idx, item))\n",
    "    \n",
    "    if len(items_to_validate) == 0:\n",
    "        logger.info(\"‚úÖ No items need validation - all extractions successful!\")\n",
    "        return {\n",
    "            **state,\n",
    "            \"validation_summary\": {\n",
    "                \"total_validated\": 0,\n",
    "                \"newly_successful\": 0,\n",
    "                \"still_failed\": 0\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    failed_count = sum(1 for _, item in items_to_validate if not item['success'])\n",
    "    retry_count = sum(1 for _, item in items_to_validate if item['success'] and item.get('needs_retry', False))\n",
    "    \n",
    "    logger.info(\"=\"*80)\n",
    "    logger.info(f\"üîç VALIDATION MANAGER: Processing {len(items_to_validate)} problematic receipts\")\n",
    "    logger.info(f\"   Failed extractions: {failed_count}\")\n",
    "    logger.info(f\"   <RETRY> placeholders: {retry_count}\")\n",
    "    logger.info(\"=\"*80)\n",
    "    \n",
    "    newly_successful = 0\n",
    "    still_failed = 0\n",
    "    \n",
    "    for idx, item in items_to_validate:\n",
    "        file_path = Path(item['file_path'])\n",
    "        \n",
    "        logger.info(f\"\\nüîç DEEP ANALYSIS: {file_path.name}\")\n",
    "        \n",
    "        if not file_path.exists():\n",
    "            logger.error(f\"   ‚ùå File not found: {file_path}\")\n",
    "            receipts_list[idx]['error'] = f\"File not found: {file_path}\"\n",
    "            receipts_list[idx]['success'] = False\n",
    "            still_failed += 1\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # Read image\n",
    "            file_ext = file_path.suffix.lower()\n",
    "            if file_ext not in [\".jpg\", \".jpeg\", \".png\"]:\n",
    "                logger.warning(f\"   ‚ö†Ô∏è  Unsupported format: {file_ext}\")\n",
    "                receipts_list[idx]['error'] = f\"Unsupported format: {file_ext}\"\n",
    "                receipts_list[idx]['success'] = False\n",
    "                still_failed += 1\n",
    "                continue\n",
    "            \n",
    "            with open(file_path, 'rb') as img_file:\n",
    "                image_bytes = img_file.read()\n",
    "                image_base64 = base64.b64encode(image_bytes).decode('utf-8')\n",
    "            \n",
    "            mime_types = {'.jpg': 'image/jpeg', '.jpeg': 'image/jpeg', '.png': 'image/png'}\n",
    "            mime_type = mime_types.get(file_ext, 'image/jpeg')\n",
    "            \n",
    "            # Build message with VALIDATION prompt\n",
    "            message = HumanMessage(\n",
    "                content=[\n",
    "                    {\"type\": \"text\", \"text\": RECEIPT_VALIDATION_PROMPT},\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\"url\": f\"data:{mime_type};base64,{image_base64}\"}\n",
    "                    }\n",
    "                ]\n",
    "            )\n",
    "            \n",
    "            # Call REASONING Vision Model (slower but more accurate)\n",
    "            logger.info(f\"   üß† Using Reasoning Model: {GROQ_VISION_REASONING_MODEL}\")\n",
    "            response = llm_vision_reasoning.invoke([message])\n",
    "            raw_response = response.content\n",
    "            \n",
    "            # Clean markdown\n",
    "            clean_json = raw_response.strip()\n",
    "            if clean_json.startswith(\"```\"):\n",
    "                clean_json = clean_json.split(\"```\")[1]\n",
    "                if clean_json.startswith(\"json\"):\n",
    "                    clean_json = clean_json[4:]\n",
    "                clean_json = clean_json.strip()\n",
    "            \n",
    "            # Parse JSON\n",
    "            try:\n",
    "                data = json.loads(clean_json)\n",
    "            except json.JSONDecodeError as json_err:\n",
    "                logger.error(f\"   ‚ùå JSON parsing failed: {json_err}\")\n",
    "                logger.error(f\"   Raw response preview: {raw_response[:200]}...\")\n",
    "                receipts_list[idx]['error'] = f\"Reasoning model JSON error: {str(json_err)}\"\n",
    "                receipts_list[idx]['success'] = False\n",
    "                still_failed += 1\n",
    "                continue  # Skip to next file\n",
    "            \n",
    "            # Validate with Pydantic\n",
    "            validated = ReceiptSchema.model_validate(data)\n",
    "            \n",
    "            # Check if still has <RETRY>\n",
    "            needs_retry, incomplete_fields = validated.check_retry_placeholders()\n",
    "            \n",
    "            if needs_retry:\n",
    "                logger.warning(f\"   ‚ö†Ô∏è  Still contains <RETRY> after deep analysis: {incomplete_fields}\")\n",
    "                receipts_list[idx]['extraction_method'] = f\"Reasoning ({GROQ_VISION_REASONING_MODEL}) - PARTIAL\"\n",
    "                receipts_list[idx]['success'] = True  # Partial success\n",
    "                receipts_list[idx]['needs_retry'] = True\n",
    "                receipts_list[idx]['incomplete_fields'] = incomplete_fields\n",
    "                receipts_list[idx]['extracted_data'] = validated.model_dump()\n",
    "                receipts_list[idx]['error'] = f\"Partial extraction with <RETRY> in: {', '.join(incomplete_fields)}\"\n",
    "                newly_successful += 1\n",
    "            else:\n",
    "                logger.info(f\"   ‚úÖ FIXED: {validated.contractor_name} - ${validated.total_value}\")\n",
    "                receipts_list[idx]['extraction_method'] = f\"Reasoning ({GROQ_VISION_REASONING_MODEL})\"\n",
    "                receipts_list[idx]['success'] = True\n",
    "                receipts_list[idx]['needs_retry'] = False\n",
    "                receipts_list[idx]['incomplete_fields'] = []\n",
    "                receipts_list[idx]['extracted_data'] = validated.model_dump()\n",
    "                receipts_list[idx]['error'] = None\n",
    "                newly_successful += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"   ‚ùå Reasoning validation failed: {e}\")\n",
    "            receipts_list[idx]['error'] = f\"Reasoning model error: {str(e)}\"\n",
    "            receipts_list[idx]['success'] = False\n",
    "            still_failed += 1\n",
    "    \n",
    "    # Convert list back to DataFrame\n",
    "    updated_df = pd.DataFrame(receipts_list)\n",
    "    \n",
    "    logger.info(\"=\"*80)\n",
    "    logger.info(f\"‚úÖ VALIDATION COMPLETE:\")\n",
    "    logger.info(f\"   Total validated: {len(items_to_validate)}\")\n",
    "    logger.info(f\"   Newly successful: {newly_successful}\")\n",
    "    logger.info(f\"   Still failed: {still_failed}\")\n",
    "    if len(items_to_validate) > 0:\n",
    "        logger.info(f\"   Success rate: {newly_successful/len(items_to_validate)*100:.1f}%\")\n",
    "    logger.info(\"=\"*80)\n",
    "    \n",
    "    return {\n",
    "        **state,\n",
    "        \"receipts_df\": updated_df,\n",
    "        \"validation_summary\": {\n",
    "            \"total_validated\": len(items_to_validate),\n",
    "            \"newly_successful\": newly_successful,\n",
    "            \"still_failed\": still_failed\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b94e79e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-05 02:11:20,732 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - ‚úÖ Database load node and function defined (normalized schema)\n"
     ]
    }
   ],
   "source": [
    "def load_to_database_node(state: dict) -> dict:\n",
    "    \"\"\"\n",
    "    üíæ DATABASE LOAD NODE: Persist validated receipts to Supabase PostgreSQL.\n",
    "    \n",
    "    Takes validated receipts from state and loads them into normalized database schema.\n",
    "    This node is part of the LangGraph pipeline and integrates seamlessly.\n",
    "    \n",
    "    Args:\n",
    "        state: Must contain \"receipts_df\" (DataFrame with validated receipts)\n",
    "    \n",
    "    Returns:\n",
    "        dict with:\n",
    "            - receipts_df: Pass-through DataFrame (unchanged)\n",
    "            - validation_summary: Pass-through validation summary\n",
    "            - load_summary: Statistics about database load\n",
    "            - errors: Updated error list\n",
    "    \"\"\"\n",
    "    receipts_df = state.get(\"receipts_df\")\n",
    "    \n",
    "    if receipts_df is None or len(receipts_df) == 0:\n",
    "        logger.warning(\"‚ö†Ô∏è  No receipts to load to database\")\n",
    "        return {\n",
    "            **state,\n",
    "            \"load_summary\": {\"error\": \"No data to load\"},\n",
    "            \"errors\": state.get(\"errors\", []) + [\"No receipts data for database load\"]\n",
    "        }\n",
    "    \n",
    "    # Call the load function\n",
    "    logger.info(\"üíæ Starting database load node...\")\n",
    "    load_result = load_receipts_to_database(receipts_df)\n",
    "    \n",
    "    # Check for errors\n",
    "    if \"error\" in load_result:\n",
    "        logger.error(f\"‚ùå Database load failed: {load_result['error']}\")\n",
    "        return {\n",
    "            **state,\n",
    "            \"load_summary\": load_result,\n",
    "            \"errors\": state.get(\"errors\", []) + [f\"Database load error: {load_result['error']}\"]\n",
    "        }\n",
    "    \n",
    "    # Success!\n",
    "    logger.info(\"‚úÖ Database load node complete\")\n",
    "    return {\n",
    "        **state,\n",
    "        \"load_summary\": load_result\n",
    "    }\n",
    "\n",
    "\n",
    "def load_receipts_to_database(df: pd.DataFrame) -> dict:\n",
    "    \"\"\"\n",
    "    üóÑÔ∏è Load validated receipt data to Supabase PostgreSQL (NORMALIZED SCHEMA).\n",
    "    \n",
    "    Takes validated_df with extracted receipt data and stores in normalized database:\n",
    "    - contractors: Unique stores/merchants\n",
    "    - receipts: Receipt transactions (FACT table with FK to contractors)\n",
    "    - line_items: Individual items (FK to receipts)\n",
    "    \n",
    "    Each receipt appears ONCE, with multiple line_items referencing it.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with 'success'=True and 'extracted_data' (ReceiptSchema)\n",
    "    \n",
    "    Returns:\n",
    "        dict with load statistics and connection info\n",
    "    \"\"\"\n",
    "    if df is None or len(df) == 0:\n",
    "        logger.warning(\"‚ùå No data to load\")\n",
    "        return {\"error\": \"No data provided\"}\n",
    "    \n",
    "    # Get Supabase connection from .env\n",
    "    db_url = os.getenv(\"DATABASE_URL\")\n",
    "    if not db_url:\n",
    "        logger.error(\"‚ùå DATABASE_URL not found in .env file\")\n",
    "        return {\"error\": \"DATABASE_URL not configured\"}\n",
    "    \n",
    "    logger.info(\"=\"*80)\n",
    "    logger.info(\"üóÑÔ∏è  LOADING RECEIPTS TO SUPABASE (NORMALIZED)\")\n",
    "    logger.info(\"=\"*80)\n",
    "    logger.info(f\"Database: {db_url.split('@')[-1]}\")\n",
    "    \n",
    "    try:\n",
    "        # Create engine and tables\n",
    "        engine = create_engine(db_url, echo=False)\n",
    "        Base.metadata.create_all(engine)\n",
    "        logger.info(\"‚úÖ Database tables created/verified (normalized schema)\")\n",
    "        \n",
    "        # Create session\n",
    "        Session = sessionmaker(bind=engine)\n",
    "        session = Session()\n",
    "        \n",
    "        # Filter only successful extractions\n",
    "        successful_df = df[df['success'] == True].copy()\n",
    "        \n",
    "        if len(successful_df) == 0:\n",
    "            logger.warning(\"‚ö†Ô∏è  No successful extractions to load\")\n",
    "            session.close()\n",
    "            return {\"warning\": \"No successful extractions\"}\n",
    "        \n",
    "        logger.info(f\"üìä Loading {len(successful_df)} receipts (normalized)...\")\n",
    "        \n",
    "        # Statistics\n",
    "        contractors_added = 0\n",
    "        receipts_added = 0\n",
    "        line_items_added = 0\n",
    "        contractor_cache = {}\n",
    "        \n",
    "        # Process each receipt\n",
    "        for idx, row in successful_df.iterrows():\n",
    "            try:\n",
    "                extracted = row['extracted_data']\n",
    "                if not extracted:\n",
    "                    continue\n",
    "                \n",
    "                contractor_name = extracted.get('contractor_name', 'Unknown')\n",
    "                \n",
    "                # Get or create contractor\n",
    "                if contractor_name not in contractor_cache:\n",
    "                    contractor = session.query(Contractor).filter_by(name=contractor_name).first()\n",
    "                    if not contractor:\n",
    "                        contractor = Contractor(name=contractor_name)\n",
    "                        session.add(contractor)\n",
    "                        session.flush()\n",
    "                        contractors_added += 1\n",
    "                        logger.info(f\"   ‚ûï New contractor: {contractor_name}\")\n",
    "                    contractor_cache[contractor_name] = contractor\n",
    "                else:\n",
    "                    contractor = contractor_cache[contractor_name]\n",
    "                \n",
    "                # Parse date\n",
    "                date_str = extracted.get('date', '')\n",
    "                try:\n",
    "                    receipt_date = dt.strptime(date_str, '%Y-%m-%d').date()\n",
    "                except:\n",
    "                    receipt_date = dt.now().date()\n",
    "                \n",
    "                # Create receipt (ONE row per receipt)\n",
    "                receipt = Receipt(\n",
    "                    document_id=extracted.get('document_id', row['filename']),\n",
    "                    filename=row['filename'],\n",
    "                    contractor_id=contractor.id,\n",
    "                    date=receipt_date,\n",
    "                    total_value=float(extracted.get('total_value', 0.0)),\n",
    "                    taxes=float(extracted.get('taxes', 0.0)),\n",
    "                    discount=float(extracted.get('discount', 0.0)),\n",
    "                    currency=extracted.get('currency', 'USD'),\n",
    "                    description=extracted.get('description'),\n",
    "                    extraction_method=row['extraction_method'],\n",
    "                    file_size_kb=row.get('file_size_kb'),\n",
    "                    needs_retry=row.get('needs_retry', False)\n",
    "                )\n",
    "                session.add(receipt)\n",
    "                session.flush()  # Get receipt.id\n",
    "                receipts_added += 1\n",
    "                \n",
    "                # Update contractor totals\n",
    "                contractor.total_receipts += 1\n",
    "                contractor.total_spent += receipt.total_value\n",
    "                \n",
    "                # Create line items (multiple rows per receipt)\n",
    "                for item_data in extracted.get('line_items', []):\n",
    "                    line_item = LineItem(\n",
    "                        receipt_id=receipt.id,  # FK to receipt\n",
    "                        description=item_data.get('description', ''),\n",
    "                        quantity=float(item_data.get('quantity', 1.0)),\n",
    "                        unit_price=float(item_data.get('unit_price', 0.0)),\n",
    "                        taxes=float(item_data.get('taxes', 0.0)),\n",
    "                        discount=float(item_data.get('discount', 0.0)),\n",
    "                        total=float(item_data.get('total', 0.0))\n",
    "                    )\n",
    "                    session.add(line_item)\n",
    "                    line_items_added += 1\n",
    "                \n",
    "                # Commit every 10 receipts\n",
    "                if receipts_added % 10 == 0:\n",
    "                    session.commit()\n",
    "                    logger.info(f\"   üíæ Committed {receipts_added} receipts...\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                logger.error(f\"   ‚ùå Error loading {row['filename']}: {e}\")\n",
    "                session.rollback()\n",
    "                continue\n",
    "        \n",
    "        # Final commit\n",
    "        session.commit()\n",
    "        session.close()\n",
    "        \n",
    "        logger.info(\"=\"*80)\n",
    "        logger.info(\"‚úÖ DATABASE LOAD COMPLETE (NORMALIZED)\")\n",
    "        logger.info(\"=\"*80)\n",
    "        logger.info(f\"   Contractors: {contractors_added} new, {len(contractor_cache)} total\")\n",
    "        logger.info(f\"   Receipts: {receipts_added} (FACT table)\")\n",
    "        logger.info(f\"   Line Items: {line_items_added} (detail table)\")\n",
    "        logger.info(f\"   Note: One receipt row per document, multiple line_items per receipt\")\n",
    "        logger.info(\"=\"*80)\n",
    "        \n",
    "        return {\n",
    "            \"success\": True,\n",
    "            \"contractors_added\": contractors_added,\n",
    "            \"contractors_total\": len(contractor_cache),\n",
    "            \"receipts_added\": receipts_added,\n",
    "            \"line_items_added\": line_items_added,\n",
    "            \"database\": db_url.split('@')[-1]\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Database error: {e}\")\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "\n",
    "logger.info(\"‚úÖ Database load node and function defined (normalized schema)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ad9bc44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-05 02:11:20,744 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - ‚úÖ Report generation node defined\n"
     ]
    }
   ],
   "source": [
    "def generate_report_node(state: dict) -> dict:\n",
    "    \"\"\"\n",
    "    üìÑ REPORT GENERATION NODE: Create markdown analysis report from database queries.\n",
    "    \n",
    "    Queries the database, generates comprehensive analysis, and saves to markdown file.\n",
    "    This node is the final step in the LangGraph pipeline.\n",
    "    \n",
    "    Args:\n",
    "        state: Must contain load_summary and other pipeline state\n",
    "    \n",
    "    Returns:\n",
    "        dict with:\n",
    "            - report_path: Path to generated report\n",
    "            - report_generated: Boolean success flag\n",
    "    \"\"\"\n",
    "    from datetime import datetime\n",
    "    \n",
    "    logger.info(\"üìÑ Starting report generation...\")\n",
    "    \n",
    "    # Check if database load was successful\n",
    "    load_summary = state.get(\"load_summary\", {})\n",
    "    if not load_summary.get(\"success\"):\n",
    "        logger.warning(\"‚ö†Ô∏è  Database load was not successful, skipping report\")\n",
    "        return {\n",
    "            **state,\n",
    "            \"report_path\": None,\n",
    "            \"report_generated\": False\n",
    "        }\n",
    "    \n",
    "    # Get database connection\n",
    "    db_url = os.getenv(\"DATABASE_URL\")\n",
    "    if not db_url:\n",
    "        logger.error(\"‚ùå DATABASE_URL not found\")\n",
    "        return {\n",
    "            **state,\n",
    "            \"report_path\": None,\n",
    "            \"report_generated\": False\n",
    "        }\n",
    "    \n",
    "    try:\n",
    "        from sqlalchemy import create_engine, text\n",
    "        engine = create_engine(db_url, echo=False)\n",
    "        \n",
    "        logger.info(\"üîç Running database queries for report...\")\n",
    "        \n",
    "        # Query 1: Overall statistics\n",
    "        query_stats = text(\"\"\"\n",
    "            WITH receipt_stats AS (\n",
    "                SELECT \n",
    "                    COUNT(DISTINCT id) as total_receipts,\n",
    "                    SUM(total_value) as total_spent,\n",
    "                    AVG(total_value) as avg_receipt_value,\n",
    "                    MAX(total_value) as max_receipt_value\n",
    "                FROM receipts\n",
    "            ),\n",
    "            contractor_stats AS (\n",
    "                SELECT COUNT(DISTINCT id) as total_contractors\n",
    "                FROM contractors\n",
    "            ),\n",
    "            line_item_stats AS (\n",
    "                SELECT COUNT(DISTINCT id) as total_line_items\n",
    "                FROM line_items\n",
    "            )\n",
    "            SELECT \n",
    "                cs.total_contractors,\n",
    "                rs.total_receipts,\n",
    "                lis.total_line_items,\n",
    "                rs.total_spent,\n",
    "                rs.avg_receipt_value,\n",
    "                rs.max_receipt_value\n",
    "            FROM contractor_stats cs, receipt_stats rs, line_item_stats lis\n",
    "        \"\"\")\n",
    "        \n",
    "        with engine.connect() as conn:\n",
    "            result = conn.execute(query_stats)\n",
    "            stats = result.fetchone()\n",
    "        \n",
    "        # Query 2: Top contractors\n",
    "        query_top = text(\"\"\"\n",
    "            SELECT \n",
    "                c.name,\n",
    "                c.total_receipts,\n",
    "                c.total_spent\n",
    "            FROM contractors c\n",
    "            ORDER BY c.total_spent DESC\n",
    "            LIMIT 10\n",
    "        \"\"\")\n",
    "        df_top_contractors = pd.read_sql(query_top, engine)\n",
    "        \n",
    "        # Query 3: Most expensive line items\n",
    "        query_items = text(\"\"\"\n",
    "            SELECT \n",
    "                li.description,\n",
    "                c.name as contractor,\n",
    "                r.document_id,\n",
    "                li.quantity,\n",
    "                li.unit_price,\n",
    "                li.total\n",
    "            FROM line_items li\n",
    "            JOIN receipts r ON li.receipt_id = r.id\n",
    "            JOIN contractors c ON r.contractor_id = c.id\n",
    "            ORDER BY li.total DESC\n",
    "            LIMIT 10\n",
    "        \"\"\")\n",
    "        df_expensive_items = pd.read_sql(query_items, engine)\n",
    "        \n",
    "        # Query 4: Receipts by extraction method\n",
    "        query_methods = text(\"\"\"\n",
    "            SELECT \n",
    "                extraction_method,\n",
    "                COUNT(*) as count,\n",
    "                SUM(total_value) as total_value,\n",
    "                AVG(total_value) as avg_value\n",
    "            FROM receipts\n",
    "            GROUP BY extraction_method\n",
    "            ORDER BY count DESC\n",
    "        \"\"\")\n",
    "        df_methods = pd.read_sql(query_methods, engine)\n",
    "        \n",
    "        logger.info(\"‚úÖ Queries complete, generating markdown report...\")\n",
    "        \n",
    "        # Generate markdown report\n",
    "        report_lines = []\n",
    "        report_lines.append(\"# üßæ Receipt Extraction Service - Analysis Report\")\n",
    "        report_lines.append(\"\")\n",
    "        report_lines.append(f\"**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        report_lines.append(f\"**Database:** {db_url.split('@')[-1]}\")\n",
    "        report_lines.append(\"\")\n",
    "        report_lines.append(\"---\")\n",
    "        report_lines.append(\"\")\n",
    "        \n",
    "        # Pipeline Summary\n",
    "        receipts_df = state.get(\"receipts_df\")\n",
    "        validation_summary = state.get(\"validation_summary\", {})\n",
    "        \n",
    "        report_lines.append(\"## üìä Pipeline Execution Summary\")\n",
    "        report_lines.append(\"\")\n",
    "        if receipts_df is not None and len(receipts_df) > 0:\n",
    "            total = len(receipts_df)\n",
    "            successful = receipts_df['success'].sum()\n",
    "            failed = total - successful\n",
    "            report_lines.append(f\"- **Total Files Processed:** {total}\")\n",
    "            report_lines.append(f\"- **Successful Extractions:** {successful} ({successful/total*100:.1f}%)\")\n",
    "            report_lines.append(f\"- **Failed Extractions:** {failed}\")\n",
    "            report_lines.append(\"\")\n",
    "            report_lines.append(f\"- **Validation Attempts:** {validation_summary.get('total_validated', 0)}\")\n",
    "            report_lines.append(f\"- **Successfully Fixed:** {validation_summary.get('newly_successful', 0)}\")\n",
    "            report_lines.append(f\"- **Still Failed:** {validation_summary.get('still_failed', 0)}\")\n",
    "        report_lines.append(\"\")\n",
    "        \n",
    "        # Database Load Summary\n",
    "        report_lines.append(\"## üíæ Database Load Summary\")\n",
    "        report_lines.append(\"\")\n",
    "        report_lines.append(f\"- **Contractors Added:** {load_summary.get('contractors_added', 0)}\")\n",
    "        report_lines.append(f\"- **Total Contractors:** {load_summary.get('contractors_total', 0)}\")\n",
    "        report_lines.append(f\"- **Receipts Loaded:** {load_summary.get('receipts_added', 0)}\")\n",
    "        report_lines.append(f\"- **Line Items Loaded:** {load_summary.get('line_items_added', 0)}\")\n",
    "        report_lines.append(\"\")\n",
    "        report_lines.append(\"---\")\n",
    "        report_lines.append(\"\")\n",
    "        \n",
    "        # Overall Statistics\n",
    "        report_lines.append(\"## üìà Overall Statistics\")\n",
    "        report_lines.append(\"\")\n",
    "        report_lines.append(f\"- **Total Contractors:** {stats[0]}\")\n",
    "        report_lines.append(f\"- **Total Receipts:** {stats[1]}\")\n",
    "        report_lines.append(f\"- **Total Line Items:** {stats[2]}\")\n",
    "        report_lines.append(f\"- **Total Spent:** ${stats[3]:,.2f}\")\n",
    "        report_lines.append(f\"- **Average Receipt Value:** ${stats[4]:,.2f}\")\n",
    "        report_lines.append(f\"- **Max Receipt Value:** ${stats[5]:,.2f}\")\n",
    "        report_lines.append(\"\")\n",
    "        \n",
    "        # Top Contractors\n",
    "        report_lines.append(\"## üí∞ Top 10 Contractors by Spending\")\n",
    "        report_lines.append(\"\")\n",
    "        report_lines.append(\"| Rank | Contractor | Total Receipts | Total Spent |\")\n",
    "        report_lines.append(\"|------|-----------|----------------|-------------|\")\n",
    "        for idx, row in df_top_contractors.iterrows():\n",
    "            report_lines.append(f\"| {idx+1} | {row['name']} | {row['total_receipts']} | ${row['total_spent']:,.2f} |\")\n",
    "        report_lines.append(\"\")\n",
    "        \n",
    "        # Most Expensive Items\n",
    "        report_lines.append(\"## üí∏ Top 10 Most Expensive Line Items\")\n",
    "        report_lines.append(\"\")\n",
    "        report_lines.append(\"| Rank | Description | Contractor | Receipt ID | Qty | Unit Price | Total |\")\n",
    "        report_lines.append(\"|------|------------|-----------|-----------|-----|-----------|-------|\")\n",
    "        for idx, row in df_expensive_items.iterrows():\n",
    "            report_lines.append(\n",
    "                f\"| {idx+1} | {row['description'][:30]}... | {row['contractor'][:20]} | \"\n",
    "                f\"{row['document_id'][:15]} | {row['quantity']:.1f} | ${row['unit_price']:.2f} | ${row['total']:.2f} |\"\n",
    "            )\n",
    "        report_lines.append(\"\")\n",
    "        \n",
    "        # Extraction Methods\n",
    "        report_lines.append(\"## ü§ñ Extraction Methods Performance\")\n",
    "        report_lines.append(\"\")\n",
    "        report_lines.append(\"| Method | Count | Total Value | Avg Value |\")\n",
    "        report_lines.append(\"|--------|-------|-------------|-----------|\")\n",
    "        for _, row in df_methods.iterrows():\n",
    "            report_lines.append(\n",
    "                f\"| {row['extraction_method']} | {row['count']} | \"\n",
    "                f\"${row['total_value']:,.2f} | ${row['avg_value']:,.2f} |\"\n",
    "            )\n",
    "        report_lines.append(\"\")\n",
    "        \n",
    "        # Footer\n",
    "        report_lines.append(\"---\")\n",
    "        report_lines.append(\"\")\n",
    "        report_lines.append(\"*Report generated by Receipt Extraction Service - AI Powered ETL Pipeline*\")\n",
    "        report_lines.append(\"\")\n",
    "        \n",
    "        # Write to file\n",
    "        report_path = DATA_OUTPUT / \"receipts_extraction_service_report.md\"\n",
    "        with open(report_path, 'w', encoding='utf-8') as f:\n",
    "            f.write('\\n'.join(report_lines))\n",
    "        \n",
    "        logger.info(\"=\"*80)\n",
    "        logger.info(\"‚úÖ REPORT GENERATION COMPLETE\")\n",
    "        logger.info(\"=\"*80)\n",
    "        logger.info(f\"   Report saved to: {report_path}\")\n",
    "        logger.info(f\"   File size: {report_path.stat().st_size / 1024:.1f} KB\")\n",
    "        logger.info(\"=\"*80)\n",
    "        \n",
    "        return {\n",
    "            **state,\n",
    "            \"report_path\": str(report_path),\n",
    "            \"report_generated\": True\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Report generation failed: {e}\")\n",
    "        return {\n",
    "            **state,\n",
    "            \"report_path\": None,\n",
    "            \"report_generated\": False\n",
    "        }\n",
    "\n",
    "\n",
    "logger.info(\"‚úÖ Report generation node defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f79d96c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924df733",
   "metadata": {},
   "source": [
    "## Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66178878",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-05 02:11:20,764 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - ‚úÖ Receipt Extraction Graph compiled successfully!\n",
      "2025-11-05 02:11:20,769 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO -    Pipeline: Extract ‚Üí Validate ‚Üí Load to Database ‚Üí Generate Report ‚Üí End\n",
      "2025-11-05 02:11:20,769 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO -    Pipeline: Extract ‚Üí Validate ‚Üí Load to Database ‚Üí Generate Report ‚Üí End\n"
     ]
    }
   ],
   "source": [
    "# Define the Receipt Extraction Graph WITH DATABASE LOAD AND REPORT\n",
    "from typing import TypedDict, Optional\n",
    "\n",
    "class ReceiptExtractionState(TypedDict, total=False):\n",
    "    \"\"\"State for the receipt extraction pipeline with database persistence and reporting.\"\"\"\n",
    "    receipt_input_path: str  # Required: Input directory path\n",
    "    receipts_df: Optional[pd.DataFrame]  # Populated by extract node\n",
    "    validation_summary: Optional[dict]  # Populated by validate node\n",
    "    load_summary: Optional[dict]  # Populated by load node\n",
    "    report_path: Optional[str]  # Populated by report node\n",
    "    report_generated: Optional[bool]  # Populated by report node\n",
    "    errors: Optional[list]  # Accumulated errors\n",
    "\n",
    "# Create the graph\n",
    "receipt_extraction_graph = StateGraph(ReceiptExtractionState)\n",
    "\n",
    "# Add nodes\n",
    "receipt_extraction_graph.add_node(\"extract_receipts\", extract_receipts_vision_node)\n",
    "receipt_extraction_graph.add_node(\"validate_receipts\", receipt_validator_manager)\n",
    "receipt_extraction_graph.add_node(\"load_to_database\", load_to_database_node)\n",
    "receipt_extraction_graph.add_node(\"generate_report\", generate_report_node)  # NEW!\n",
    "\n",
    "# Define edges (pipeline flow)\n",
    "receipt_extraction_graph.add_edge(START, \"extract_receipts\")\n",
    "receipt_extraction_graph.add_edge(\"extract_receipts\", \"validate_receipts\")\n",
    "receipt_extraction_graph.add_edge(\"validate_receipts\", \"load_to_database\")\n",
    "receipt_extraction_graph.add_edge(\"load_to_database\", \"generate_report\")  # NEW!\n",
    "receipt_extraction_graph.add_edge(\"generate_report\", END)\n",
    "\n",
    "# Compile the graph\n",
    "receipt_pipeline = receipt_extraction_graph.compile()\n",
    "\n",
    "logger.info(\"‚úÖ Receipt Extraction Graph compiled successfully!\")\n",
    "logger.info(\"   Pipeline: Extract ‚Üí Validate ‚Üí Load to Database ‚Üí Generate Report ‚Üí End\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d24a362e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x11901f7a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(receipt_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb7c8f7",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "398cfa6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-05 02:11:21,741 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - üöÄ Starting Complete Receipt Extraction Pipeline (Extract ‚Üí Validate ‚Üí Load ‚Üí Report)...\n",
      "2025-11-05 02:11:21,746 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - üì∏ Processing 11 receipts with Vision Model (LangChain)...\n",
      "2025-11-05 02:11:21,746 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - [1/11] Processing: 0.jpg\n",
      "2025-11-05 02:11:21,746 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - üì∏ Processing 11 receipts with Vision Model (LangChain)...\n",
      "2025-11-05 02:11:21,746 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - [1/11] Processing: 0.jpg\n",
      "2025-11-05 02:11:22,662 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-05 02:11:22,668 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO -    ‚úÖ Extracted: WALMART - $5.11\n",
      "2025-11-05 02:11:22,669 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - [2/11] Processing: 1.jpg\n",
      "2025-11-05 02:11:22,662 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-05 02:11:22,668 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO -    ‚úÖ Extracted: WALMART - $5.11\n",
      "2025-11-05 02:11:22,669 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - [2/11] Processing: 1.jpg\n",
      "2025-11-05 02:11:26,183 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-05 02:11:26,188 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO -    ‚úÖ Extracted: Trader Joe's - $38.68\n",
      "2025-11-05 02:11:26,188 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - [3/11] Processing: 10.jpg\n",
      "2025-11-05 02:11:26,183 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-05 02:11:26,188 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO -    ‚úÖ Extracted: Trader Joe's - $38.68\n",
      "2025-11-05 02:11:26,188 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - [3/11] Processing: 10.jpg\n",
      "2025-11-05 02:11:29,191 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-05 02:11:29,194 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO -    ‚úÖ Extracted: SPAR - $338.16\n",
      "2025-11-05 02:11:29,195 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - [4/11] Processing: 2.jpg\n",
      "2025-11-05 02:11:29,191 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-05 02:11:29,194 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO -    ‚úÖ Extracted: SPAR - $338.16\n",
      "2025-11-05 02:11:29,195 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - [4/11] Processing: 2.jpg\n",
      "2025-11-05 02:11:30,502 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-05 02:11:30,504 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO -    ‚úÖ Extracted: Walmart - $49.9\n",
      "2025-11-05 02:11:30,505 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - [5/11] Processing: 3.jpg\n",
      "2025-11-05 02:11:30,502 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-05 02:11:30,504 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO -    ‚úÖ Extracted: Walmart - $49.9\n",
      "2025-11-05 02:11:30,505 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - [5/11] Processing: 3.jpg\n",
      "2025-11-05 02:11:35,031 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-05 02:11:35,037 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO -    ‚úÖ Extracted: Walmart - $144.02\n",
      "2025-11-05 02:11:35,038 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - [6/11] Processing: 4.jpg\n",
      "2025-11-05 02:11:35,031 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-05 02:11:35,037 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO -    ‚úÖ Extracted: Walmart - $144.02\n",
      "2025-11-05 02:11:35,038 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - [6/11] Processing: 4.jpg\n",
      "2025-11-05 02:11:36,039 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-05 02:11:36,043 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO -    ‚ö†Ô∏è  Extracted with <RETRY> fields: Walmart - ['line_items']\n",
      "2025-11-05 02:11:36,043 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - [7/11] Processing: 5.jpg\n",
      "2025-11-05 02:11:36,039 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-05 02:11:36,043 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO -    ‚ö†Ô∏è  Extracted with <RETRY> fields: Walmart - ['line_items']\n",
      "2025-11-05 02:11:36,043 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - [7/11] Processing: 5.jpg\n",
      "2025-11-05 02:11:39,021 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-05 02:11:39,024 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO -    ‚úÖ Extracted: Whole Foods Market - $28.28\n",
      "2025-11-05 02:11:39,025 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - [8/11] Processing: 6.JPG\n",
      "2025-11-05 02:11:39,021 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-05 02:11:39,024 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO -    ‚úÖ Extracted: Whole Foods Market - $28.28\n",
      "2025-11-05 02:11:39,025 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - [8/11] Processing: 6.JPG\n",
      "2025-11-05 02:11:40,789 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-05 02:11:40,792 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO -    ‚úÖ Extracted: Momi & Toy's Cr√™perie - $175000.0\n",
      "2025-11-05 02:11:40,792 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - [9/11] Processing: 7.jpg\n",
      "2025-11-05 02:11:40,789 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-05 02:11:40,792 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO -    ‚úÖ Extracted: Momi & Toy's Cr√™perie - $175000.0\n",
      "2025-11-05 02:11:40,792 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - [9/11] Processing: 7.jpg\n",
      "2025-11-05 02:11:41,920 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-05 02:11:41,924 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO -    ‚úÖ Extracted: Walmart - $23.19\n",
      "2025-11-05 02:11:41,925 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - [10/11] Processing: 8.jpg\n",
      "2025-11-05 02:11:41,920 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-05 02:11:41,924 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO -    ‚úÖ Extracted: Walmart - $23.19\n",
      "2025-11-05 02:11:41,925 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - [10/11] Processing: 8.jpg\n",
      "2025-11-05 02:11:42,608 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-05 02:11:42,617 - RECEIPTS-SERVICE__ai-powered-etl-process - ERROR -    ‚ùå JSON parsing failed for 8.jpg: Expecting value: line 6 column 18 (char 123)\n",
      "2025-11-05 02:11:42,618 - RECEIPTS-SERVICE__ai-powered-etl-process - ERROR -    Raw response preview: ```\n",
      "{\n",
      "  \"document_id\": \"<RETRY>\",\n",
      "  \"contractor_name\": \"<RETRY>\",\n",
      "  \"client_name\": null,\n",
      "  \"date\": \"<RETRY>\",\n",
      "  \"total_value\": <RETRY>,\n",
      "  \"currency\": \"USD\",\n",
      "  \"description\": \"<RETRY>\",\n",
      "  \"line_items\":...\n",
      "2025-11-05 02:11:42,618 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - [11/11] Processing: 9.jpg\n",
      "2025-11-05 02:11:42,608 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-05 02:11:42,617 - RECEIPTS-SERVICE__ai-powered-etl-process - ERROR -    ‚ùå JSON parsing failed for 8.jpg: Expecting value: line 6 column 18 (char 123)\n",
      "2025-11-05 02:11:42,618 - RECEIPTS-SERVICE__ai-powered-etl-process - ERROR -    Raw response preview: ```\n",
      "{\n",
      "  \"document_id\": \"<RETRY>\",\n",
      "  \"contractor_name\": \"<RETRY>\",\n",
      "  \"client_name\": null,\n",
      "  \"date\": \"<RETRY>\",\n",
      "  \"total_value\": <RETRY>,\n",
      "  \"currency\": \"USD\",\n",
      "  \"description\": \"<RETRY>\",\n",
      "  \"line_items\":...\n",
      "2025-11-05 02:11:42,618 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - [11/11] Processing: 9.jpg\n",
      "2025-11-05 02:11:48,049 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-05 02:11:48,057 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO -    ‚úÖ Extracted: WinCo FOODS - $121.92\n",
      "2025-11-05 02:11:48,049 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-05 02:11:48,057 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO -    ‚úÖ Extracted: WinCo FOODS - $121.92\n",
      "2025-11-05 02:11:48,063 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - ================================================================================\n",
      "2025-11-05 02:11:48,064 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - ‚úÖ Vision Model Extraction Complete:\n",
      "2025-11-05 02:11:48,065 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO -    Total: 11 receipts\n",
      "2025-11-05 02:11:48,066 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO -    Successful: 10 (90.9%)\n",
      "2025-11-05 02:11:48,067 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO -    Failed: 1\n",
      "2025-11-05 02:11:48,067 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - ================================================================================\n",
      "2025-11-05 02:11:48,063 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - ================================================================================\n",
      "2025-11-05 02:11:48,064 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - ‚úÖ Vision Model Extraction Complete:\n",
      "2025-11-05 02:11:48,065 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO -    Total: 11 receipts\n",
      "2025-11-05 02:11:48,066 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO -    Successful: 10 (90.9%)\n",
      "2025-11-05 02:11:48,067 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO -    Failed: 1\n",
      "2025-11-05 02:11:48,067 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - ================================================================================\n",
      "2025-11-05 02:11:48,076 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - ================================================================================\n",
      "2025-11-05 02:11:48,080 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - üîç VALIDATION MANAGER: Processing 2 problematic receipts\n",
      "2025-11-05 02:11:48,089 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO -    Failed extractions: 1\n",
      "2025-11-05 02:11:48,090 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO -    <RETRY> placeholders: 1\n",
      "2025-11-05 02:11:48,093 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - ================================================================================\n",
      "2025-11-05 02:11:48,094 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - \n",
      "üîç DEEP ANALYSIS: 4.jpg\n",
      "2025-11-05 02:11:48,095 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO -    üß† Using Reasoning Model: meta-llama/llama-4-maverick-17b-128e-instruct\n",
      "2025-11-05 02:11:48,076 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - ================================================================================\n",
      "2025-11-05 02:11:48,080 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - üîç VALIDATION MANAGER: Processing 2 problematic receipts\n",
      "2025-11-05 02:11:48,089 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO -    Failed extractions: 1\n",
      "2025-11-05 02:11:48,090 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO -    <RETRY> placeholders: 1\n",
      "2025-11-05 02:11:48,093 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - ================================================================================\n",
      "2025-11-05 02:11:48,094 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - \n",
      "üîç DEEP ANALYSIS: 4.jpg\n",
      "2025-11-05 02:11:48,095 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO -    üß† Using Reasoning Model: meta-llama/llama-4-maverick-17b-128e-instruct\n",
      "2025-11-05 02:11:48,979 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-05 02:11:48,982 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO -    ‚úÖ FIXED: Walmart - $7.43\n",
      "2025-11-05 02:11:48,983 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - \n",
      "üîç DEEP ANALYSIS: 8.jpg\n",
      "2025-11-05 02:11:48,985 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO -    üß† Using Reasoning Model: meta-llama/llama-4-maverick-17b-128e-instruct\n",
      "2025-11-05 02:11:48,979 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-05 02:11:48,982 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO -    ‚úÖ FIXED: Walmart - $7.43\n",
      "2025-11-05 02:11:48,983 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - \n",
      "üîç DEEP ANALYSIS: 8.jpg\n",
      "2025-11-05 02:11:48,985 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO -    üß† Using Reasoning Model: meta-llama/llama-4-maverick-17b-128e-instruct\n",
      "2025-11-05 02:11:50,246 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-05 02:11:50,251 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO -    ‚úÖ FIXED: COSTCO WHOLESALE - $89.13\n",
      "2025-11-05 02:11:50,254 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - ================================================================================\n",
      "2025-11-05 02:11:50,255 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - ‚úÖ VALIDATION COMPLETE:\n",
      "2025-11-05 02:11:50,255 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO -    Total validated: 2\n",
      "2025-11-05 02:11:50,246 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-05 02:11:50,251 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO -    ‚úÖ FIXED: COSTCO WHOLESALE - $89.13\n",
      "2025-11-05 02:11:50,254 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - ================================================================================\n",
      "2025-11-05 02:11:50,255 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - ‚úÖ VALIDATION COMPLETE:\n",
      "2025-11-05 02:11:50,255 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO -    Total validated: 2\n",
      "2025-11-05 02:11:50,256 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO -    Newly successful: 2\n",
      "2025-11-05 02:11:50,257 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO -    Still failed: 0\n",
      "2025-11-05 02:11:50,256 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO -    Newly successful: 2\n",
      "2025-11-05 02:11:50,257 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO -    Still failed: 0\n",
      "2025-11-05 02:11:50,258 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO -    Success rate: 100.0%\n",
      "2025-11-05 02:11:50,259 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - ================================================================================\n",
      "2025-11-05 02:11:50,264 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - üíæ Starting database load node...\n",
      "2025-11-05 02:11:50,265 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - ================================================================================\n",
      "2025-11-05 02:11:50,266 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - üóÑÔ∏è  LOADING RECEIPTS TO SUPABASE (NORMALIZED)\n",
      "2025-11-05 02:11:50,266 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - ================================================================================\n",
      "2025-11-05 02:11:50,258 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO -    Success rate: 100.0%\n",
      "2025-11-05 02:11:50,259 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - ================================================================================\n",
      "2025-11-05 02:11:50,264 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - üíæ Starting database load node...\n",
      "2025-11-05 02:11:50,265 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - ================================================================================\n",
      "2025-11-05 02:11:50,266 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - üóÑÔ∏è  LOADING RECEIPTS TO SUPABASE (NORMALIZED)\n",
      "2025-11-05 02:11:50,266 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - ================================================================================\n",
      "2025-11-05 02:11:50,266 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - Database: db.lqgtsioqjjufbqdixbdk.supabase.co:5432/postgres\n",
      "2025-11-05 02:11:50,266 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - Database: db.lqgtsioqjjufbqdixbdk.supabase.co:5432/postgres\n",
      "WARNING:  invalid configuration parameter name \"supautils.disable_program\", removing it\n",
      "DETAIL:  \"supautils\" is now a reserved prefix.\n",
      "WARNING:  invalid configuration parameter name \"supautils.disable_program\", removing it\n",
      "DETAIL:  \"supautils\" is now a reserved prefix.\n",
      "2025-11-05 02:11:53,654 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - ‚úÖ Database tables created/verified (normalized schema)\n",
      "2025-11-05 02:11:53,654 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - ‚úÖ Database tables created/verified (normalized schema)\n",
      "2025-11-05 02:11:53,658 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - üìä Loading 11 receipts (normalized)...\n",
      "2025-11-05 02:11:53,658 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - üìä Loading 11 receipts (normalized)...\n",
      "2025-11-05 02:11:59,637 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO -    üíæ Committed 10 receipts...\n",
      "2025-11-05 02:11:59,637 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO -    üíæ Committed 10 receipts...\n",
      "2025-11-05 02:12:00,491 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - ================================================================================\n",
      "2025-11-05 02:12:00,492 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - ‚úÖ DATABASE LOAD COMPLETE (NORMALIZED)\n",
      "2025-11-05 02:12:00,493 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - ================================================================================\n",
      "2025-11-05 02:12:00,494 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO -    Contractors: 0 new, 8 total\n",
      "2025-11-05 02:12:00,494 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO -    Receipts: 11 (FACT table)\n",
      "2025-11-05 02:12:00,495 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO -    Line Items: 114 (detail table)\n",
      "2025-11-05 02:12:00,497 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO -    Note: One receipt row per document, multiple line_items per receipt\n",
      "2025-11-05 02:12:00,498 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - ================================================================================\n",
      "2025-11-05 02:12:00,499 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - ‚úÖ Database load node complete\n",
      "2025-11-05 02:12:00,491 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - ================================================================================\n",
      "2025-11-05 02:12:00,492 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - ‚úÖ DATABASE LOAD COMPLETE (NORMALIZED)\n",
      "2025-11-05 02:12:00,493 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - ================================================================================\n",
      "2025-11-05 02:12:00,494 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO -    Contractors: 0 new, 8 total\n",
      "2025-11-05 02:12:00,494 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO -    Receipts: 11 (FACT table)\n",
      "2025-11-05 02:12:00,495 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO -    Line Items: 114 (detail table)\n",
      "2025-11-05 02:12:00,497 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO -    Note: One receipt row per document, multiple line_items per receipt\n",
      "2025-11-05 02:12:00,498 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - ================================================================================\n",
      "2025-11-05 02:12:00,499 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - ‚úÖ Database load node complete\n",
      "2025-11-05 02:12:00,506 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - üìÑ Starting report generation...\n",
      "2025-11-05 02:12:00,507 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - üîç Running database queries for report...\n",
      "2025-11-05 02:12:00,506 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - üìÑ Starting report generation...\n",
      "2025-11-05 02:12:00,507 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - üîç Running database queries for report...\n",
      "WARNING:  invalid configuration parameter name \"supautils.disable_program\", removing it\n",
      "DETAIL:  \"supautils\" is now a reserved prefix.\n",
      "WARNING:  invalid configuration parameter name \"supautils.disable_program\", removing it\n",
      "DETAIL:  \"supautils\" is now a reserved prefix.\n",
      "2025-11-05 02:12:05,226 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - ‚úÖ Queries complete, generating markdown report...\n",
      "2025-11-05 02:12:05,230 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - ================================================================================\n",
      "2025-11-05 02:12:05,231 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - ‚úÖ REPORT GENERATION COMPLETE\n",
      "2025-11-05 02:12:05,231 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - ================================================================================\n",
      "2025-11-05 02:12:05,231 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO -    Report saved to: /Users/viniciusgribas/Code/github/work/teste_alvorada_dev/data/output/receipts_extraction_service_report.md\n",
      "2025-11-05 02:12:05,232 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO -    File size: 2.6 KB\n",
      "2025-11-05 02:12:05,232 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - ================================================================================\n",
      "2025-11-05 02:12:05,226 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - ‚úÖ Queries complete, generating markdown report...\n",
      "2025-11-05 02:12:05,230 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - ================================================================================\n",
      "2025-11-05 02:12:05,231 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - ‚úÖ REPORT GENERATION COMPLETE\n",
      "2025-11-05 02:12:05,231 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - ================================================================================\n",
      "2025-11-05 02:12:05,231 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO -    Report saved to: /Users/viniciusgribas/Code/github/work/teste_alvorada_dev/data/output/receipts_extraction_service_report.md\n",
      "2025-11-05 02:12:05,232 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO -    File size: 2.6 KB\n",
      "2025-11-05 02:12:05,232 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - ================================================================================\n",
      "2025-11-05 02:12:05,241 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - ================================================================================\n",
      "2025-11-05 02:12:05,242 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - üéØ PIPELINE EXECUTION COMPLETE\n",
      "2025-11-05 02:12:05,242 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - ================================================================================\n",
      "2025-11-05 02:12:05,243 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - Total receipts processed: 11\n",
      "2025-11-05 02:12:05,243 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - Successful extractions: 11\n",
      "2025-11-05 02:12:05,244 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - Failed extractions: 0\n",
      "2025-11-05 02:12:05,244 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - Success rate: 100.0%\n",
      "2025-11-05 02:12:05,245 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - ================================================================================\n",
      "2025-11-05 02:12:05,241 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - ================================================================================\n",
      "2025-11-05 02:12:05,242 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - üéØ PIPELINE EXECUTION COMPLETE\n",
      "2025-11-05 02:12:05,242 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - ================================================================================\n",
      "2025-11-05 02:12:05,243 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - Total receipts processed: 11\n",
      "2025-11-05 02:12:05,243 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - Successful extractions: 11\n",
      "2025-11-05 02:12:05,244 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - Failed extractions: 0\n",
      "2025-11-05 02:12:05,244 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - Success rate: 100.0%\n",
      "2025-11-05 02:12:05,245 - RECEIPTS-SERVICE__ai-powered-etl-process - INFO - ================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Pipeline Results:\n",
      "   Total receipts: 11\n",
      "   Successful: 11 (100.0%)\n",
      "   Failed: 0\n",
      "\n",
      "üìà Validation Summary:\n",
      "   Items validated: 2\n",
      "   Successfully fixed: 2\n",
      "   Still failed: 0\n",
      "\n",
      "üíæ Database Load Summary:\n",
      "   ‚úÖ Load successful!\n",
      "   Database: db.lqgtsioqjjufbqdixbdk.supabase.co:5432/postgres\n",
      "   Contractors: 0 new, 8 total\n",
      "   Receipts: 11 rows\n",
      "   Line Items: 114\n",
      "\n",
      "üìÑ Report Generation:\n",
      "   ‚úÖ Report generated successfully!\n",
      "   üìÅ Location: /Users/viniciusgribas/Code/github/work/teste_alvorada_dev/data/output/receipts_extraction_service_report.md\n",
      "   üìè Size: 2.6 KB\n"
     ]
    }
   ],
   "source": [
    "# Execute the complete Receipt Extraction Pipeline WITH DATABASE LOAD AND REPORT\n",
    "logger.info(\"üöÄ Starting Complete Receipt Extraction Pipeline (Extract ‚Üí Validate ‚Üí Load ‚Üí Report)...\")\n",
    "\n",
    "# Define initial state (ONLY required field: receipt_input_path)\n",
    "initial_state = {\n",
    "    \"receipt_input_path\": str(RECEIPTS_DIR)\n",
    "}\n",
    "\n",
    "# Execute the graph (all other fields populated by nodes)\n",
    "final_state = receipt_pipeline.invoke(initial_state)\n",
    "\n",
    "# Extract results\n",
    "receipts_df = final_state[\"receipts_df\"]\n",
    "validation_summary = final_state.get(\"validation_summary\", {})\n",
    "load_summary = final_state.get(\"load_summary\", {})\n",
    "report_path = final_state.get(\"report_path\")\n",
    "report_generated = final_state.get(\"report_generated\", False)\n",
    "\n",
    "# Display summary\n",
    "logger.info(\"=\"*80)\n",
    "logger.info(\"üéØ PIPELINE EXECUTION COMPLETE\")\n",
    "logger.info(\"=\"*80)\n",
    "logger.info(f\"Total receipts processed: {len(receipts_df)}\")\n",
    "logger.info(f\"Successful extractions: {receipts_df['success'].sum()}\")\n",
    "logger.info(f\"Failed extractions: {(~receipts_df['success']).sum()}\")\n",
    "logger.info(f\"Success rate: {receipts_df['success'].sum()/len(receipts_df)*100:.1f}%\")\n",
    "logger.info(\"=\"*80)\n",
    "\n",
    "print(\"\\nüìä Pipeline Results:\")\n",
    "print(f\"   Total receipts: {len(receipts_df)}\")\n",
    "print(f\"   Successful: {receipts_df['success'].sum()} ({receipts_df['success'].sum()/len(receipts_df)*100:.1f}%)\")\n",
    "print(f\"   Failed: {(~receipts_df['success']).sum()}\")\n",
    "\n",
    "print(f\"\\nüìà Validation Summary:\")\n",
    "print(f\"   Items validated: {validation_summary.get('total_validated', 0)}\")\n",
    "print(f\"   Successfully fixed: {validation_summary.get('newly_successful', 0)}\")\n",
    "print(f\"   Still failed: {validation_summary.get('still_failed', 0)}\")\n",
    "\n",
    "print(f\"\\nüíæ Database Load Summary:\")\n",
    "if load_summary.get('success'):\n",
    "    print(f\"   ‚úÖ Load successful!\")\n",
    "    print(f\"   Database: {load_summary.get('database', 'N/A')}\")\n",
    "    print(f\"   Contractors: {load_summary.get('contractors_added', 0)} new, {load_summary.get('contractors_total', 0)} total\")\n",
    "    print(f\"   Receipts: {load_summary.get('receipts_added', 0)} rows\")\n",
    "    print(f\"   Line Items: {load_summary.get('line_items_added', 0)}\")\n",
    "elif 'error' in load_summary:\n",
    "    print(f\"   ‚ùå Load failed: {load_summary['error']}\")\n",
    "elif 'warning' in load_summary:\n",
    "    print(f\"   ‚ö†Ô∏è  {load_summary['warning']}\")\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è  No load summary available\")\n",
    "\n",
    "print(f\"\\nüìÑ Report Generation:\")\n",
    "if report_generated and report_path:\n",
    "    print(f\"   ‚úÖ Report generated successfully!\")\n",
    "    print(f\"   üìÅ Location: {report_path}\")\n",
    "    from pathlib import Path\n",
    "    report_file = Path(report_path)\n",
    "    if report_file.exists():\n",
    "        print(f\"   üìè Size: {report_file.stat().st_size / 1024:.1f} KB\")\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è  Report not generated\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7619960b",
   "metadata": {},
   "source": [
    "# TESTS AND DEBUG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551d8fed",
   "metadata": {},
   "source": [
    "## Test Node - Extract Receipts with Vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f30a4099",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'huhuhhu' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mhuhuhhu\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'huhuhhu' is not defined"
     ]
    }
   ],
   "source": [
    "huhuhhu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e55cb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "receipts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a26aba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and normalize the extracted_data column\n",
    "extracted_data_df = pd.json_normalize(receipts_df['extracted_data'])\n",
    "extracted_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92b01d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and normalize the line_items column\n",
    "line_itens_data_df = pd.json_normalize(extracted_data_df['line_items'])\n",
    "line_itens_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfbf06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TEST 1: Supabase Connection\n",
    "# ============================================================================\n",
    "\n",
    "print(\"üß™ Testing Supabase PostgreSQL Connection\\n\")\n",
    "\n",
    "# Reload .env to get DATABASE_URL\n",
    "load_dotenv(override=True)\n",
    "db_url = os.getenv(\"DATABASE_URL\")\n",
    "\n",
    "if not db_url:\n",
    "    print(\"‚ùå DATABASE_URL not found!\")\n",
    "    print(\"\\nüí° Add to your .env file:\")\n",
    "    print(\"DATABASE_URL=postgresql://user:password@host:port/database\")\n",
    "else:\n",
    "    print(f\"‚úÖ DATABASE_URL found\")\n",
    "    \n",
    "    # Test connection\n",
    "    try:\n",
    "        from sqlalchemy import create_engine, text\n",
    "        engine = create_engine(db_url, echo=False)\n",
    "        \n",
    "        with engine.connect() as conn:\n",
    "            result = conn.execute(text(\"SELECT version();\"))\n",
    "            version = result.fetchone()[0]\n",
    "        \n",
    "        print(f\"‚úÖ Connection successful!\")\n",
    "        print(f\"   PostgreSQL: {version.split()[0]} {version.split()[1]}\")\n",
    "        \n",
    "        if 'supabase.com' in db_url:\n",
    "            print(f\"   Provider: Supabase (Cloud)\")\n",
    "        \n",
    "        print(\"\\nÔøΩ Ready to load receipt data!\")\n",
    "        print(\"   Run the next cell to insert validated_df\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Connection failed: {e}\")\n",
    "        print(\"\\nüí° Check:\")\n",
    "        print(\"   1. DATABASE_URL is correct\")\n",
    "        print(\"   2. Supabase project is active\")\n",
    "        print(\"   3. Network connectivity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66674cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query and analyze PostgreSQL data\n",
    "# Run SQL queries to explore the loaded data\n",
    "\n",
    "db_url = os.getenv(\"DATABASE_URL\")\n",
    "if not db_url:\n",
    "    print(\"‚ùå DATABASE_URL not set\")\n",
    "else:\n",
    "    try:\n",
    "        # Create pandas SQL connection\n",
    "        from sqlalchemy import create_engine, text\n",
    "        engine = create_engine(db_url, echo=False)\n",
    "        \n",
    "        print(\"üîç POSTGRESQL DATA ANALYSIS\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # Query 1: Overall statistics (FIXED: Avoid multiplication from JOINs)\n",
    "        query_stats = text(\"\"\"\n",
    "            WITH receipt_stats AS (\n",
    "                SELECT \n",
    "                    COUNT(DISTINCT id) as total_receipts,\n",
    "                    SUM(total_value) as total_spent,\n",
    "                    AVG(total_value) as avg_receipt_value,\n",
    "                    MAX(total_value) as max_receipt_value\n",
    "                FROM receipts\n",
    "            ),\n",
    "            contractor_stats AS (\n",
    "                SELECT COUNT(DISTINCT id) as total_contractors\n",
    "                FROM contractors\n",
    "            ),\n",
    "            line_item_stats AS (\n",
    "                SELECT COUNT(DISTINCT id) as total_line_items\n",
    "                FROM line_items\n",
    "            )\n",
    "            SELECT \n",
    "                cs.total_contractors,\n",
    "                rs.total_receipts,\n",
    "                lis.total_line_items,\n",
    "                rs.total_spent,\n",
    "                rs.avg_receipt_value,\n",
    "                rs.max_receipt_value\n",
    "            FROM contractor_stats cs, receipt_stats rs, line_item_stats lis\n",
    "        \"\"\")\n",
    "        \n",
    "        with engine.connect() as conn:\n",
    "            result = conn.execute(query_stats)\n",
    "            stats = result.fetchone()\n",
    "            \n",
    "        print(\"\\nüìä OVERALL STATISTICS:\")\n",
    "        print(f\"   Total Contractors: {stats[0]}\")\n",
    "        print(f\"   Total Receipts: {stats[1]}\")\n",
    "        print(f\"   Total Line Items: {stats[2]}\")\n",
    "        print(f\"   Total Spent: ${stats[3]:.2f}\")\n",
    "        print(f\"   Average Receipt: ${stats[4]:.2f}\")\n",
    "        print(f\"   Max Receipt: ${stats[5]:.2f}\")\n",
    "        \n",
    "        # Query 2: Top contractors\n",
    "        query_top = text(\"\"\"\n",
    "            SELECT \n",
    "                c.name,\n",
    "                c.total_receipts,\n",
    "                c.total_spent\n",
    "            FROM contractors c\n",
    "            ORDER BY c.total_spent DESC\n",
    "            LIMIT 10\n",
    "        \"\"\")\n",
    "        \n",
    "        df_top_contractors = pd.read_sql(query_top, engine)\n",
    "        print(\"\\nüí∞ TOP 10 CONTRACTORS BY SPENDING:\")\n",
    "        print(df_top_contractors.to_string(index=False))\n",
    "        \n",
    "        # Query 3: Most expensive line items\n",
    "        query_items = text(\"\"\"\n",
    "            SELECT \n",
    "                li.description,\n",
    "                c.name as contractor,\n",
    "                r.document_id,\n",
    "                li.quantity,\n",
    "                li.unit_price,\n",
    "                li.total\n",
    "            FROM line_items li\n",
    "            JOIN receipts r ON li.receipt_id = r.id\n",
    "            JOIN contractors c ON r.contractor_id = c.id\n",
    "            ORDER BY li.total DESC\n",
    "            LIMIT 10\n",
    "        \"\"\")\n",
    "        \n",
    "        df_expensive_items = pd.read_sql(query_items, engine)\n",
    "        print(\"\\nüí∏ TOP 10 MOST EXPENSIVE LINE ITEMS:\")\n",
    "        print(df_expensive_items.to_string(index=False))\n",
    "        \n",
    "        # Query 4: Receipts by extraction method\n",
    "        query_methods = text(\"\"\"\n",
    "            SELECT \n",
    "                extraction_method,\n",
    "                COUNT(*) as count,\n",
    "                SUM(total_value) as total_value,\n",
    "                AVG(total_value) as avg_value\n",
    "            FROM receipts\n",
    "            GROUP BY extraction_method\n",
    "            ORDER BY count DESC\n",
    "        \"\"\")\n",
    "        \n",
    "        df_methods = pd.read_sql(query_methods, engine)\n",
    "        print(\"\\nü§ñ EXTRACTION METHODS:\")\n",
    "        print(df_methods.to_string(index=False))\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"‚úÖ Query complete\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Query failed: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "etl-pipeline-pdfs",
   "language": "python",
   "name": "etl-pipeline-pdfs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
